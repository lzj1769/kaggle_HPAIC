(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-21 17:03:53.744627: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-21 17:03:54.012642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 17:03:54.218063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 17:03:54.218121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-21 17:03:56.829127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-21 17:03:56.829165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-21 17:03:56.829173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-21 17:03:56.829176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-21 17:03:56.829826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-21 17:03:56.980197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-22 15:43:52.391745: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-22 15:43:52.652362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-22 15:43:52.861601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-22 15:43:52.861666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-22 15:43:55.394328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-22 15:43:55.394361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-22 15:43:55.394370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-22 15:43:55.394374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-22 15:43:55.395120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-22 15:43:55.556336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

Process PoolWorker-153:
Process PoolWorker-146:
Process PoolWorker-158:
Process PoolWorker-154:
Process PoolWorker-155:
Process PoolWorker-160:
Process PoolWorker-159:
Process PoolWorker-157:
Traceback (most recent call last):
Traceback (most recent call last):
Process PoolWorker-156:
Process PoolWorker-149:
Process PoolWorker-147:
Process PoolWorker-145:
Traceback (most recent call last):
Process PoolWorker-152:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
Process PoolWorker-150:
Traceback (most recent call last):
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self.run()
    self.run()
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self.run()
    self.run()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 376, in get
    task = get()
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    task = get()
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    task = get()
KeyboardInterrupt
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    racquire()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    racquire()
    task = get()
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
KeyboardInterrupt
KeyboardInterrupt
    return recv()
    racquire()
    racquire()
    racquire()
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
    self.run()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    task = get()
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    racquire()
KeyboardInterrupt
    racquire()
    task = get()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 376, in get
KeyboardInterrupt
KeyboardInterrupt
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    return recv()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
KeyboardInterrupt
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    racquire()
KeyboardInterrupt
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 97, in generate_data
    batch_x /= 255.
KeyboardInterrupt
Process PoolWorker-151:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
    img = np.array(self.x[index], copy=True)
KeyboardInterrupt
Process PoolWorker-148:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
    img = np.array(self.x[index], copy=True)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 139, in <module>
    main()
  File "train.py", line 132, in main
    max_queue_size=max_queue_size)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training_generator.py", line 217, in fit_generator
    class_weight=class_weight)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training.py", line 1217, in train_on_batch
    outputs = self.train_function(ins)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/home/rs619065/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1451, in __call__
    self._session._session, self._handle, args, status, None)
KeyboardInterrupt
(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-24 11:29:29.423336: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-24 11:29:29.686586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-24 11:29:29.894942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-24 11:29:29.895004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-24 11:29:30.492496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-24 11:29:30.492530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-24 11:29:30.492539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-24 11:29:30.492542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-24 11:29:30.493216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-24 11:29:30.643539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
