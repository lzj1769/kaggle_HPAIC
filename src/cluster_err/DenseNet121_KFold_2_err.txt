(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-21 12:19:05.670665: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-21 12:19:05.941599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 12:19:06.144651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 12:19:06.144705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-21 12:19:09.990551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-21 12:19:09.990586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-21 12:19:09.990596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-21 12:19:09.990600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-21 12:19:09.991339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-21 12:19:10.145266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-21 21:38:49.033595: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-21 21:38:49.292216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 21:38:49.499381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 21:38:49.499443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-21 21:38:50.090455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-21 21:38:50.090490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-21 21:38:50.090499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-21 21:38:50.090502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-21 21:38:50.091175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-21 21:38:50.238847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
Error in atexit._run_exitfuncs:Process PoolWorker-489:

Process PoolWorker-491:
Process PoolWorker-490:
Process PoolWorker-495:
Process PoolWorker-492:
Process PoolWorker-496:
Process PoolWorker-493:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/atexit.py", line 24, in _run_exitfuncs
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    func(*targs, **kargs)
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 299, in _exit_function
    _run_finalizers(0)
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 268, in _run_finalizers
    finalizer()
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 201, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 487, in _terminate_pool
    outqueue.put(None)                  # sentinel
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    wacquire()
KeyboardInterrupt
Error in sys.exitfunc:
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self.run()
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    self.run()
    self.run()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    task = get()
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    put((job, i, result))
    put((job, i, result))
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    wacquire()
    racquire()
    wacquire()
    wacquire()
    wacquire()
    wacquire()
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
    wacquire()
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/lib64/python2.7/atexit.py", line 24, in _run_exitfuncs
    func(*targs, **kargs)
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 299, in _exit_function
    _run_finalizers(0)
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 268, in _run_finalizers
    finalizer()
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 201, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 487, in _terminate_pool
    outqueue.put(None)                  # sentinel
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    wacquire()
KeyboardInterrupt
Process PoolWorker-494:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 390, in put
    return send(obj)
KeyboardInterrupt
(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-23 10:17:08.798053: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-23 10:17:09.062494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-23 10:17:09.271796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-23 10:17:09.271858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-23 10:17:12.544931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-23 10:17:12.544962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-23 10:17:12.544969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-23 10:17:12.544973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-23 10:17:12.545653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-23 10:17:12.699797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
