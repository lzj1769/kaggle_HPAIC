(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-21 12:18:44.489900: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-21 12:18:44.748848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 12:18:44.951668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 12:18:44.951732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-21 12:18:45.544219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-21 12:18:45.544256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-21 12:18:45.544264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-21 12:18:45.544268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-21 12:18:45.544924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-21 12:18:45.694456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

Error in atexit._run_exitfuncs:
Process PoolWorker-169:
Traceback (most recent call last):
Process PoolWorker-175:
Process PoolWorker-176:
Process PoolWorker-171:
Process PoolWorker-172:
Process PoolWorker-174:
  File "/usr/lib64/python2.7/atexit.py", line 24, in _run_exitfuncs
Process PoolWorker-170:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    func(*targs, **kargs)
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 299, in _exit_function
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    _run_finalizers(0)
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 268, in _run_finalizers
    finalizer()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 201, in __call__
    self.run()
    res = self._callback(*self._args, **self._kwargs)
    self.run()
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 487, in _terminate_pool
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    outqueue.put(None)                  # sentinel
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    self.run()
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
KeyboardInterrupt
    racquire()
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
KeyboardInterrupt
    wacquire()
    wacquire()
    self.run()
    self.run()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
KeyboardInterrupt
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
KeyboardInterrupt
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
Error in sys.exitfunc:
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    wacquire()
KeyboardInterrupt
    put((job, i, result))
    put((job, i, result))
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    wacquire()
    wacquire()
    wacquire()
Traceback (most recent call last):
  File "/usr/lib64/python2.7/atexit.py", line 24, in _run_exitfuncs
    func(*targs, **kargs)
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 299, in _exit_function
    _run_finalizers(0)
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 268, in _run_finalizers
KeyboardInterrupt
    finalizer()
  File "/usr/lib64/python2.7/multiprocessing/util.py", line 201, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 487, in _terminate_pool
KeyboardInterrupt
KeyboardInterrupt
    outqueue.put(None)                  # sentinel
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 388, in put
    wacquire()
KeyboardInterrupt
Process PoolWorker-173:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 117, in worker
    put((job, i, result))
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 390, in put
    return send(obj)
KeyboardInterrupt
(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-21 21:30:09.869506: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-21 21:30:10.141115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 21:30:10.347416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 21:30:10.347472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-21 21:30:13.860553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-21 21:30:13.860591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-21 21:30:13.860600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-21 21:30:13.860604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-21 21:30:13.861346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-21 21:30:14.015179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-23 09:18:52.170283: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-23 09:18:52.433515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-23 09:18:52.640909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-23 09:18:52.640966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-23 09:18:56.640832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-23 09:18:56.640871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-23 09:18:56.640880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-23 09:18:56.640883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-23 09:18:56.641608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-23 09:18:56.793407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
Process PoolWorker-1368:
Process PoolWorker-1361:
Process PoolWorker-1371:
Process PoolWorker-1376:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Process PoolWorker-1375:
Process PoolWorker-1365:
Process PoolWorker-1374:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Process PoolWorker-1369:
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Process PoolWorker-1370:
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Process PoolWorker-1364:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Process PoolWorker-1373:
    self.run()
Traceback (most recent call last):
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Process PoolWorker-1372:
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    self.run()
    self._target(*self._args, **self._kwargs)
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    task = get()
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 376, in get
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
    self.run()
    task = get()
    self.run()
    self.run()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    self._target(*self._args, **self._kwargs)
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 376, in get
    racquire()
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
KeyboardInterrupt
    task = get()
    return recv()
    racquire()
KeyboardInterrupt
KeyboardInterrupt
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
KeyboardInterrupt
    return recv()
    task = get()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
KeyboardInterrupt
    task = get()
    task = get()
    task = get()
KeyboardInterrupt
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    racquire()
KeyboardInterrupt
    racquire()
KeyboardInterrupt
    racquire()
    racquire()
    racquire()
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
Process PoolWorker-1367:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
    img = np.array(self.x[index], copy=True)
KeyboardInterrupt
Process PoolWorker-1362:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
    img = np.array(self.x[index], copy=True)
KeyboardInterrupt
Process PoolWorker-1363:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
    img = np.array(self.x[index], copy=True)
KeyboardInterrupt
Process PoolWorker-1366:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
    img = np.array(self.x[index], copy=True)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 139, in <module>
    main()
  File "train.py", line 132, in main
    max_queue_size=max_queue_size)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training_generator.py", line 217, in fit_generator
    class_weight=class_weight)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training.py", line 1217, in train_on_batch
    outputs = self.train_function(ins)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/home/rs619065/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1451, in __call__
    self._session._session, self._handle, args, status, None)
KeyboardInterrupt
