(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-21 12:18:19.856077: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-21 12:18:20.120008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 12:18:20.333039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 12:18:20.333116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-21 12:18:21.065421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-21 12:18:21.065465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-21 12:18:21.065476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-21 12:18:21.065480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-21 12:18:21.066221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-21 12:18:21.234522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-21 19:33:08.709025: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-21 19:33:08.967774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 19:33:09.181411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-21 19:33:09.181471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-21 19:33:11.772147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-21 19:33:11.772182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-21 19:33:11.772190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-21 19:33:11.772193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-21 19:33:11.772868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-21 19:33:11.920042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
(OK) Loading cuda 9.0.176
(OK) Loading cudnn 7.0.5
/home/rs619065/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
load the model configuration...
===========================================================================

2018-12-22 22:52:42.990563: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-22 22:52:43.261048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-22 22:52:43.469007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0000:84:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-12-22 22:52:43.469063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-12-22 22:52:46.360765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-22 22:52:46.360801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-12-22 22:52:46.360810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-12-22 22:52:46.360813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-12-22 22:52:46.361538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15135 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-12-22 22:52:46.514287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15135 MB memory) -> physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
load training and validation data...
===========================================================================

training model...
===========================================================================

/home/rs619065/.local/lib/python2.7/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
Process PoolWorker-976:
Process PoolWorker-969:
Process PoolWorker-970:
Process PoolWorker-973:
Process PoolWorker-975:
Process PoolWorker-974:
Process PoolWorker-972:
Process PoolWorker-971:
Process PoolWorker-961:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Process PoolWorker-967:
Traceback (most recent call last):
Process PoolWorker-963:
Process PoolWorker-964:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
Process PoolWorker-962:
Process PoolWorker-966:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
    self.run()
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
    self._target(*self._args, **self._kwargs)
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    task = get()
    task = get()
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    task = get()
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 376, in get
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 376, in get
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    self.run()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    self.run()
    racquire()
    return recv()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    racquire()
    return recv()
    self._target(*self._args, **self._kwargs)
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
KeyboardInterrupt
KeyboardInterrupt
    task = get()
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
KeyboardInterrupt
KeyboardInterrupt
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
KeyboardInterrupt
KeyboardInterrupt
KeyboardInterrupt
    task = get()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
KeyboardInterrupt
KeyboardInterrupt
    racquire()
KeyboardInterrupt
    task = get()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
KeyboardInterrupt
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
    self.run()
    racquire()
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 102, in worker
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    task = get()
  File "/usr/lib64/python2.7/multiprocessing/queues.py", line 374, in get
    racquire()
    racquire()
KeyboardInterrupt
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 139, in <module>
    main()
  File "train.py", line 132, in main
    max_queue_size=max_queue_size)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training_generator.py", line 217, in fit_generator
Process PoolWorker-965:
    class_weight=class_weight)
Traceback (most recent call last):
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/engine/training.py", line 1217, in train_on_batch
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    outputs = self.train_function(ins)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return self._call(inputs)
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
Process PoolWorker-968:
Traceback (most recent call last):
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib64/python2.7/multiprocessing/process.py", line 114, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib64/python2.7/multiprocessing/pool.py", line 113, in worker
    fetched = self._callable_fn(*array_vals)
  File "/home/rs619065/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1451, in __call__
    result = (True, func(*args, **kwds))
  File "/home/rs619065/.local/lib/python2.7/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    return _SHARED_SEQUENCES[uid][i]
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 68, in __getitem__
    batch_x = self.generate_data(indexes)
    batch_x = self.generate_data(indexes)
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
  File "/rwthfs/rz/cluster/home/rs619065/HPAIC/src/generator.py", line 85, in generate_data
    img = np.array(self.x[index], copy=True)
    img = np.array(self.x[index], copy=True)
KeyboardInterrupt
KeyboardInterrupt
    self._session._session, self._handle, args, status, None)
KeyboardInterrupt
