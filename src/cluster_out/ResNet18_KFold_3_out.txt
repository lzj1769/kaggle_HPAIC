Sender: LSF System <lsfadmin@lng05>
Subject: Job 46184809: <ResNet18_KFold_3> in cluster <rcc> Done

Job <ResNet18_KFold_3> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 12 01:29:51 2018
Job was executed on host(s) <lng05>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 12 09:49:05 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 12 09:49:05 2018
Terminated at Mon Dec 17 00:12:48 2018
Results reported at Mon Dec 17 00:12:48 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 3
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1179033.50 sec.
    Max Memory :                                 42373 MB
    Average Memory :                             36190.09 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               60027.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              38
    Max Threads :                                873
    Run time :                                   397423 sec.
    Turnaround time :                            427377 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 64)           0           res2a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           res3a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 256)          0           res4a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 512)          0           res5a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1472)         0           global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
                                                                 global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 512)          754176      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc2[0][0]                        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,639,644
Trainable params: 13,627,868
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84510 samples, validate on 21167 samples
Epoch 1/100
 - 8087s - loss: 0.3250 - binary_accuracy: 0.8644 - val_loss: 0.1507 - val_binary_accuracy: 0.9514

Epoch 00001: val_loss improved from inf to 0.15068994, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 2/100
 - 8527s - loss: 0.1520 - binary_accuracy: 0.9511 - val_loss: 0.1776 - val_binary_accuracy: 0.9472

Epoch 00002: val_loss did not improve from 0.15068994
Epoch 3/100
 - 8015s - loss: 0.1346 - binary_accuracy: 0.9559 - val_loss: 0.1287 - val_binary_accuracy: 0.9573

Epoch 00003: val_loss improved from 0.15068994 to 0.12873516, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 4/100
 - 7976s - loss: 0.1258 - binary_accuracy: 0.9584 - val_loss: 0.1173 - val_binary_accuracy: 0.9611

Epoch 00004: val_loss improved from 0.12873516 to 0.11726203, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 5/100
 - 7732s - loss: 0.1205 - binary_accuracy: 0.9600 - val_loss: 0.1160 - val_binary_accuracy: 0.9628

Epoch 00005: val_loss improved from 0.11726203 to 0.11600494, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 6/100
 - 6406s - loss: 0.1169 - binary_accuracy: 0.9610 - val_loss: 0.1163 - val_binary_accuracy: 0.9615

Epoch 00006: val_loss did not improve from 0.11600494
Epoch 7/100
 - 5516s - loss: 0.1140 - binary_accuracy: 0.9619 - val_loss: 0.1210 - val_binary_accuracy: 0.9598

Epoch 00007: val_loss did not improve from 0.11600494
Epoch 8/100
 - 5189s - loss: 0.1123 - binary_accuracy: 0.9624 - val_loss: 0.1090 - val_binary_accuracy: 0.9639

Epoch 00008: val_loss improved from 0.11600494 to 0.10895141, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 9/100
 - 4939s - loss: 0.1102 - binary_accuracy: 0.9630 - val_loss: 0.1088 - val_binary_accuracy: 0.9640

Epoch 00009: val_loss improved from 0.10895141 to 0.10883355, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 10/100
 - 4981s - loss: 0.1090 - binary_accuracy: 0.9634 - val_loss: 0.1069 - val_binary_accuracy: 0.9643

Epoch 00010: val_loss improved from 0.10883355 to 0.10686711, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 11/100
 - 8798s - loss: 0.1079 - binary_accuracy: 0.9638 - val_loss: 0.1137 - val_binary_accuracy: 0.9616

Epoch 00011: val_loss did not improve from 0.10686711
Epoch 12/100
 - 6345s - loss: 0.1065 - binary_accuracy: 0.9641 - val_loss: 0.1162 - val_binary_accuracy: 0.9615

Epoch 00012: val_loss did not improve from 0.10686711
Epoch 13/100
 - 6215s - loss: 0.1055 - binary_accuracy: 0.9645 - val_loss: 0.1077 - val_binary_accuracy: 0.9638

Epoch 00013: val_loss did not improve from 0.10686711
Epoch 14/100
 - 6782s - loss: 0.1046 - binary_accuracy: 0.9647 - val_loss: 0.1009 - val_binary_accuracy: 0.9668

Epoch 00014: val_loss improved from 0.10686711 to 0.10085560, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 15/100
 - 6059s - loss: 0.1041 - binary_accuracy: 0.9649 - val_loss: 0.1006 - val_binary_accuracy: 0.9672

Epoch 00015: val_loss improved from 0.10085560 to 0.10061619, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 16/100
 - 6400s - loss: 0.1032 - binary_accuracy: 0.9653 - val_loss: 0.0998 - val_binary_accuracy: 0.9670

Epoch 00016: val_loss improved from 0.10061619 to 0.09982368, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 17/100
 - 6163s - loss: 0.1028 - binary_accuracy: 0.9654 - val_loss: 0.1014 - val_binary_accuracy: 0.9657

Epoch 00017: val_loss did not improve from 0.09982368
Epoch 18/100
 - 6632s - loss: 0.1019 - binary_accuracy: 0.9657 - val_loss: 0.0976 - val_binary_accuracy: 0.9678

Epoch 00018: val_loss improved from 0.09982368 to 0.09762493, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 19/100
 - 11423s - loss: 0.1019 - binary_accuracy: 0.9657 - val_loss: 0.1054 - val_binary_accuracy: 0.9663

Epoch 00019: val_loss did not improve from 0.09762493
Epoch 20/100
 - 14802s - loss: 0.1013 - binary_accuracy: 0.9660 - val_loss: 0.1005 - val_binary_accuracy: 0.9670

Epoch 00020: val_loss did not improve from 0.09762493
Epoch 21/100
 - 12809s - loss: 0.1012 - binary_accuracy: 0.9660 - val_loss: 0.0952 - val_binary_accuracy: 0.9682

Epoch 00021: val_loss improved from 0.09762493 to 0.09516069, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 22/100
 - 5954s - loss: 0.1008 - binary_accuracy: 0.9661 - val_loss: 0.1022 - val_binary_accuracy: 0.9664

Epoch 00022: val_loss did not improve from 0.09516069
Epoch 23/100
 - 9082s - loss: 0.1004 - binary_accuracy: 0.9663 - val_loss: 0.0993 - val_binary_accuracy: 0.9668

Epoch 00023: val_loss did not improve from 0.09516069
Epoch 24/100
 - 6507s - loss: 0.1001 - binary_accuracy: 0.9665 - val_loss: 0.0972 - val_binary_accuracy: 0.9682

Epoch 00024: val_loss did not improve from 0.09516069
Epoch 25/100
 - 7491s - loss: 0.0999 - binary_accuracy: 0.9664 - val_loss: 0.1024 - val_binary_accuracy: 0.9660

Epoch 00025: val_loss did not improve from 0.09516069
Epoch 26/100
 - 10554s - loss: 0.0994 - binary_accuracy: 0.9667 - val_loss: 0.0947 - val_binary_accuracy: 0.9688

Epoch 00026: val_loss improved from 0.09516069 to 0.09465170, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 27/100
 - 7529s - loss: 0.0989 - binary_accuracy: 0.9668 - val_loss: 0.0954 - val_binary_accuracy: 0.9689

Epoch 00027: val_loss did not improve from 0.09465170
Epoch 28/100
 - 7865s - loss: 0.0987 - binary_accuracy: 0.9669 - val_loss: 0.0922 - val_binary_accuracy: 0.9683

Epoch 00028: val_loss improved from 0.09465170 to 0.09221083, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 29/100
 - 6339s - loss: 0.0986 - binary_accuracy: 0.9670 - val_loss: 0.1035 - val_binary_accuracy: 0.9677

Epoch 00029: val_loss did not improve from 0.09221083
Epoch 30/100
 - 6468s - loss: 0.0985 - binary_accuracy: 0.9670 - val_loss: 0.0961 - val_binary_accuracy: 0.9687

Epoch 00030: val_loss did not improve from 0.09221083
Epoch 31/100
 - 8019s - loss: 0.0981 - binary_accuracy: 0.9673 - val_loss: 0.1057 - val_binary_accuracy: 0.9646

Epoch 00031: val_loss did not improve from 0.09221083
Epoch 32/100
 - 11880s - loss: 0.0981 - binary_accuracy: 0.9672 - val_loss: 0.1018 - val_binary_accuracy: 0.9680

Epoch 00032: val_loss did not improve from 0.09221083
Epoch 33/100
 - 7970s - loss: 0.0978 - binary_accuracy: 0.9674 - val_loss: 0.1063 - val_binary_accuracy: 0.9678

Epoch 00033: val_loss did not improve from 0.09221083
Epoch 34/100
 - 8949s - loss: 0.0978 - binary_accuracy: 0.9673 - val_loss: 0.0960 - val_binary_accuracy: 0.9694

Epoch 00034: val_loss did not improve from 0.09221083
Epoch 35/100
 - 6176s - loss: 0.0976 - binary_accuracy: 0.9673 - val_loss: 0.0967 - val_binary_accuracy: 0.9680

Epoch 00035: val_loss did not improve from 0.09221083
Epoch 36/100
 - 5522s - loss: 0.0972 - binary_accuracy: 0.9675 - val_loss: 0.1112 - val_binary_accuracy: 0.9668

Epoch 00036: val_loss did not improve from 0.09221083
Epoch 37/100
 - 5632s - loss: 0.0974 - binary_accuracy: 0.9676 - val_loss: 0.0921 - val_binary_accuracy: 0.9690

Epoch 00037: val_loss improved from 0.09221083 to 0.09210388, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 38/100
 - 5602s - loss: 0.0973 - binary_accuracy: 0.9676 - val_loss: 0.0984 - val_binary_accuracy: 0.9695

Epoch 00038: val_loss did not improve from 0.09210388
Epoch 39/100
 - 5429s - loss: 0.0969 - binary_accuracy: 0.9677 - val_loss: 0.0944 - val_binary_accuracy: 0.9695

Epoch 00039: val_loss did not improve from 0.09210388
Epoch 40/100
 - 5400s - loss: 0.0969 - binary_accuracy: 0.9677 - val_loss: 0.0971 - val_binary_accuracy: 0.9690

Epoch 00040: val_loss did not improve from 0.09210388
Epoch 41/100
 - 5457s - loss: 0.0968 - binary_accuracy: 0.9677 - val_loss: 0.0931 - val_binary_accuracy: 0.9698

Epoch 00041: val_loss did not improve from 0.09210388
Epoch 42/100
 - 5469s - loss: 0.0967 - binary_accuracy: 0.9679 - val_loss: 0.1125 - val_binary_accuracy: 0.9660

Epoch 00042: val_loss did not improve from 0.09210388
Epoch 43/100
 - 5554s - loss: 0.0964 - binary_accuracy: 0.9678 - val_loss: 0.0953 - val_binary_accuracy: 0.9687

Epoch 00043: val_loss did not improve from 0.09210388
Epoch 44/100
 - 5526s - loss: 0.0964 - binary_accuracy: 0.9679 - val_loss: 0.0933 - val_binary_accuracy: 0.9702

Epoch 00044: val_loss did not improve from 0.09210388
Epoch 45/100
 - 5440s - loss: 0.0962 - binary_accuracy: 0.9679 - val_loss: 0.0930 - val_binary_accuracy: 0.9696

Epoch 00045: val_loss did not improve from 0.09210388
Epoch 46/100
 - 5456s - loss: 0.0960 - binary_accuracy: 0.9680 - val_loss: 0.0923 - val_binary_accuracy: 0.9698

Epoch 00046: val_loss did not improve from 0.09210388
Epoch 47/100
 - 5514s - loss: 0.0960 - binary_accuracy: 0.9680 - val_loss: 0.0898 - val_binary_accuracy: 0.9708

Epoch 00047: val_loss improved from 0.09210388 to 0.08976843, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 48/100
 - 5489s - loss: 0.0959 - binary_accuracy: 0.9680 - val_loss: 0.1103 - val_binary_accuracy: 0.9691

Epoch 00048: val_loss did not improve from 0.08976843
Epoch 49/100
 - 5519s - loss: 0.0956 - binary_accuracy: 0.9682 - val_loss: 0.0926 - val_binary_accuracy: 0.9702

Epoch 00049: val_loss did not improve from 0.08976843
Epoch 50/100
 - 5511s - loss: 0.0953 - binary_accuracy: 0.9682 - val_loss: 0.0937 - val_binary_accuracy: 0.9701

Epoch 00050: val_loss did not improve from 0.08976843
Epoch 51/100

Epoch 00050: val_loss did not improve from 0.08976843
 - 5508s - loss: 0.0952 - binary_accuracy: 0.9682 - val_loss: 0.0904 - val_binary_accuracy: 0.9704

Epoch 00051: val_loss did not improve from 0.08976843
Epoch 52/100
 - 5447s - loss: 0.0951 - binary_accuracy: 0.9684 - val_loss: 0.1000 - val_binary_accuracy: 0.9686

Epoch 00052: val_loss did not improve from 0.08976843
Epoch 53/100
 - 5441s - loss: 0.0948 - binary_accuracy: 0.9685 - val_loss: 0.0863 - val_binary_accuracy: 0.9710

Epoch 00053: val_loss improved from 0.08976843 to 0.08630425, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 54/100
 - 5563s - loss: 0.0947 - binary_accuracy: 0.9684 - val_loss: 0.0891 - val_binary_accuracy: 0.9709

Epoch 00054: val_loss did not improve from 0.08630425
Epoch 55/100
 - 5505s - loss: 0.0948 - binary_accuracy: 0.9685 - val_loss: 0.0879 - val_binary_accuracy: 0.9714

Epoch 00055: val_loss did not improve from 0.08630425
Epoch 56/100
 - 5655s - loss: 0.0947 - binary_accuracy: 0.9685 - val_loss: 0.0880 - val_binary_accuracy: 0.9710

Epoch 00056: val_loss did not improve from 0.08630425
Epoch 57/100
 - 5549s - loss: 0.0945 - binary_accuracy: 0.9686 - val_loss: 0.0939 - val_binary_accuracy: 0.9691

Epoch 00057: val_loss did not improve from 0.08630425
Epoch 58/100

Epoch 00057: val_loss did not improve from 0.08630425
 - 5532s - loss: 0.0940 - binary_accuracy: 0.9687 - val_loss: 0.0912 - val_binary_accuracy: 0.9708

Epoch 00058: val_loss did not improve from 0.08630425
Stopping after 396000 seconds.
complete!!


PS:

Read file <./cluster_err/ResNet18_KFold_3_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng08>
Subject: Job 46227121: <ResNet18_KFold_3> in cluster <rcc> Exited

Job <ResNet18_KFold_3> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Tue Dec 18 19:13:09 2018
Job was executed on host(s) <lng08>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Tue Dec 18 19:41:59 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Tue Dec 18 19:41:59 2018
Terminated at Wed Dec 19 13:41:25 2018
Results reported at Wed Dec 19 13:41:25 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 3
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   250001.19 sec.
    Max Memory :                                 40413 MB
    Average Memory :                             35939.65 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               61987.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   64766 sec.
    Turnaround time :                            66496 sec.

The output (if any) follows:

Training model on 84510 samples, validate on 21167 samples
Epoch 1/100
 - 5258s - loss: 0.0918 - binary_accuracy: 0.9695 - val_loss: 0.0836 - val_binary_accuracy: 0.9725

Epoch 00001: val_loss improved from 0.08630425 to 0.08360514, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 2/100
 - 5456s - loss: 0.0912 - binary_accuracy: 0.9696 - val_loss: 0.0821 - val_binary_accuracy: 0.9726

Epoch 00002: val_loss improved from 0.08360514 to 0.08207208, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 3/100
 - 5446s - loss: 0.0909 - binary_accuracy: 0.9699 - val_loss: 0.0827 - val_binary_accuracy: 0.9726

Epoch 00003: val_loss did not improve from 0.08207208
Epoch 4/100
 - 5443s - loss: 0.0908 - binary_accuracy: 0.9698 - val_loss: 0.0815 - val_binary_accuracy: 0.9727

Epoch 00004: val_loss improved from 0.08207208 to 0.08146784, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 5/100
 - 5467s - loss: 0.0906 - binary_accuracy: 0.9699 - val_loss: 0.0813 - val_binary_accuracy: 0.9727

Epoch 00005: val_loss improved from 0.08146784 to 0.08126126, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 6/100
 - 5183s - loss: 0.0905 - binary_accuracy: 0.9699 - val_loss: 0.0816 - val_binary_accuracy: 0.9728

Epoch 00006: val_loss did not improve from 0.08126126
Epoch 7/100
 - 5354s - loss: 0.0903 - binary_accuracy: 0.9700 - val_loss: 0.0808 - val_binary_accuracy: 0.9730

Epoch 00007: val_loss improved from 0.08126126 to 0.08075262, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 8/100
 - 5497s - loss: 0.0902 - binary_accuracy: 0.9701 - val_loss: 0.0813 - val_binary_accuracy: 0.9727

Epoch 00008: val_loss did not improve from 0.08075262
Epoch 9/100
 - 5272s - loss: 0.0902 - binary_accuracy: 0.9701 - val_loss: 0.0813 - val_binary_accuracy: 0.9728

Epoch 00009: val_loss did not improve from 0.08075262
Epoch 10/100
 - 5403s - loss: 0.0900 - binary_accuracy: 0.9701 - val_loss: 0.0816 - val_binary_accuracy: 0.9730

Epoch 00010: val_loss did not improve from 0.08075262
Epoch 11/100
 - 5366s - loss: 0.0902 - binary_accuracy: 0.9700 - val_loss: 0.0815 - val_binary_accuracy: 0.9727

Epoch 00011: val_loss did not improve from 0.08075262
Epoch 12/100
 - 5068s - loss: 0.0899 - binary_accuracy: 0.9701 - val_loss: 0.0808 - val_binary_accuracy: 0.9729

Epoch 00012: val_loss did not improve from 0.08075262
Epoch 13/100


PS:

Read file <./cluster_err/ResNet18_KFold_3_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng05>
Subject: Job 46232801: <ResNet18_KFold_3> in cluster <rcc> Exited

Job <ResNet18_KFold_3> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 19 13:55:15 2018
Job was executed on host(s) <lng05>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 19 16:32:22 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 19 16:32:22 2018
Terminated at Thu Dec 20 18:18:43 2018
Results reported at Thu Dec 20 18:18:43 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 3
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   398486.75 sec.
    Max Memory :                                 42867 MB
    Average Memory :                             38324.12 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               59533.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              38
    Max Threads :                                873
    Run time :                                   92781 sec.
    Turnaround time :                            102208 sec.

The output (if any) follows:

Training model on 84510 samples, validate on 21167 samples
Epoch 1/100
Epoch 1/100
 - 3613s - loss: 0.0826 - binary_accuracy: 0.9720 - val_loss: 0.0806 - val_binary_accuracy: 0.9730

Epoch 00001: val_loss improved from 0.08075262 to 0.08064157, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 2/100
 - 3520s - loss: 0.0821 - binary_accuracy: 0.9721 - val_loss: 0.0806 - val_binary_accuracy: 0.9730

Epoch 00002: val_loss improved from 0.08064157 to 0.08055873, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 3/100
 - 3566s - loss: 0.0820 - binary_accuracy: 0.9722 - val_loss: 0.0797 - val_binary_accuracy: 0.9730

Epoch 00003: val_loss improved from 0.08055873 to 0.07974160, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 4/100
 - 3559s - loss: 0.0818 - binary_accuracy: 0.9723 - val_loss: 0.0796 - val_binary_accuracy: 0.9730

Epoch 00004: val_loss improved from 0.07974160 to 0.07960531, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 5/100
 - 3621s - loss: 0.0817 - binary_accuracy: 0.9724 - val_loss: 0.0794 - val_binary_accuracy: 0.9731

Epoch 00005: val_loss improved from 0.07960531 to 0.07936766, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 6/100
 - 3695s - loss: 0.0814 - binary_accuracy: 0.9724 - val_loss: 0.0792 - val_binary_accuracy: 0.9732

Epoch 00006: val_loss improved from 0.07936766 to 0.07924390, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 7/100
 - 4817s - loss: 0.0812 - binary_accuracy: 0.9725 - val_loss: 0.0794 - val_binary_accuracy: 0.9732

Epoch 00007: val_loss did not improve from 0.07924390
Epoch 8/100
 - 4093s - loss: 0.0813 - binary_accuracy: 0.9725 - val_loss: 0.0799 - val_binary_accuracy: 0.9730

Epoch 00008: val_loss did not improve from 0.07924390
Epoch 9/100
 - 4283s - loss: 0.0811 - binary_accuracy: 0.9725 - val_loss: 0.0797 - val_binary_accuracy: 0.9731

Epoch 00009: val_loss did not improve from 0.07924390
Epoch 10/100
 - 5221s - loss: 0.0809 - binary_accuracy: 0.9727 - val_loss: 0.0798 - val_binary_accuracy: 0.9729

Epoch 00010: val_loss did not improve from 0.07924390
Epoch 11/100
 - 5268s - loss: 0.0810 - binary_accuracy: 0.9725 - val_loss: 0.0790 - val_binary_accuracy: 0.9732

Epoch 00011: val_loss improved from 0.07924390 to 0.07896953, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 12/100
 - 5255s - loss: 0.0807 - binary_accuracy: 0.9727 - val_loss: 0.0790 - val_binary_accuracy: 0.9731

Epoch 00012: val_loss did not improve from 0.07896953
Epoch 13/100
 - 5209s - loss: 0.0807 - binary_accuracy: 0.9727 - val_loss: 0.0785 - val_binary_accuracy: 0.9733

Epoch 00013: val_loss improved from 0.07896953 to 0.07850357, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 14/100
 - 5061s - loss: 0.0805 - binary_accuracy: 0.9727 - val_loss: 0.0790 - val_binary_accuracy: 0.9730

Epoch 00014: val_loss did not improve from 0.07850357
Epoch 15/100
 - 5379s - loss: 0.0806 - binary_accuracy: 0.9727 - val_loss: 0.0786 - val_binary_accuracy: 0.9731

Epoch 00015: val_loss did not improve from 0.07850357
Epoch 16/100
 - 5294s - loss: 0.0804 - binary_accuracy: 0.9727 - val_loss: 0.0788 - val_binary_accuracy: 0.9733

Epoch 00016: val_loss did not improve from 0.07850357
Epoch 17/100
 - 5225s - loss: 0.0803 - binary_accuracy: 0.9728 - val_loss: 0.0785 - val_binary_accuracy: 0.9732

Epoch 00017: val_loss improved from 0.07850357 to 0.07845102, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 18/100
 - 5132s - loss: 0.0803 - binary_accuracy: 0.9727 - val_loss: 0.0788 - val_binary_accuracy: 0.9730

Epoch 00018: val_loss did not improve from 0.07845102
Epoch 19/100
 - 5340s - loss: 0.0800 - binary_accuracy: 0.9728 - val_loss: 0.0788 - val_binary_accuracy: 0.9733

Epoch 00019: val_loss did not improve from 0.07845102
Epoch 20/100
 - 5380s - loss: 0.0799 - binary_accuracy: 0.9728 - val_loss: 0.0789 - val_binary_accuracy: 0.9731

Epoch 00020: val_loss did not improve from 0.07845102
Epoch 21/100


PS:

Read file <./cluster_err/ResNet18_KFold_3_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng05>
Subject: Job 46356131: <ResNet18_KFold_3> in cluster <rcc> Exited

Job <ResNet18_KFold_3> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Mon Dec 31 10:37:01 2018
Job was executed on host(s) <lng05>, in queue <normal>, as user <rs619065> in cluster <rcc> at Wed Jan  2 16:21:52 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Jan  2 16:21:52 2019
Terminated at Sun Jan  6 18:59:23 2019
Results reported at Sun Jan  6 18:59:23 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 3
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   906698.50 sec.
    Max Memory :                                 36358 MB
    Average Memory :                             29954.73 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               43642.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              21
    Max Threads :                                474
    Run time :                                   355050 sec.
    Turnaround time :                            548542 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 512)          262656      global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc2[0][0]                        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,148,124
Trainable params: 13,136,348
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84510 samples, validate on 21167 samples
Epoch 1/100
 - 7100s - loss: 0.2247 - binary_accuracy: 0.9153 - val_loss: 0.1512 - val_binary_accuracy: 0.9481

Epoch 00001: val_loss improved from inf to 0.15115068, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 2/100
 - 6852s - loss: 0.1248 - binary_accuracy: 0.9583 - val_loss: 0.1266 - val_binary_accuracy: 0.9575

Epoch 00002: val_loss improved from 0.15115068 to 0.12658967, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 3/100
 - 6603s - loss: 0.1145 - binary_accuracy: 0.9615 - val_loss: 0.1262 - val_binary_accuracy: 0.9562

Epoch 00003: val_loss improved from 0.12658967 to 0.12620601, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 4/100
 - 6470s - loss: 0.1086 - binary_accuracy: 0.9632 - val_loss: 0.1085 - val_binary_accuracy: 0.9638

Epoch 00004: val_loss improved from 0.12620601 to 0.10854297, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 5/100
 - 6492s - loss: 0.1048 - binary_accuracy: 0.9644 - val_loss: 0.1182 - val_binary_accuracy: 0.9610

Epoch 00005: val_loss did not improve from 0.10854297
Epoch 6/100
 - 6728s - loss: 0.1024 - binary_accuracy: 0.9652 - val_loss: 0.1008 - val_binary_accuracy: 0.9662

Epoch 00006: val_loss improved from 0.10854297 to 0.10075973, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 7/100
 - 6397s - loss: 0.1001 - binary_accuracy: 0.9659 - val_loss: 0.1003 - val_binary_accuracy: 0.9664

Epoch 00007: val_loss improved from 0.10075973 to 0.10032158, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 8/100
 - 6387s - loss: 0.0984 - binary_accuracy: 0.9664 - val_loss: 0.0994 - val_binary_accuracy: 0.9661

Epoch 00008: val_loss improved from 0.10032158 to 0.09944126, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 9/100
 - 6451s - loss: 0.0967 - binary_accuracy: 0.9671 - val_loss: 0.1005 - val_binary_accuracy: 0.9656

Epoch 00009: val_loss did not improve from 0.09944126
Epoch 10/100
 - 6652s - loss: 0.0960 - binary_accuracy: 0.9673 - val_loss: 0.0944 - val_binary_accuracy: 0.9684

Epoch 00010: val_loss improved from 0.09944126 to 0.09440515, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 11/100
 - 6589s - loss: 0.0947 - binary_accuracy: 0.9677 - val_loss: 0.0916 - val_binary_accuracy: 0.9691

Epoch 00011: val_loss improved from 0.09440515 to 0.09164047, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 12/100
 - 6023s - loss: 0.0940 - binary_accuracy: 0.9680 - val_loss: 0.0954 - val_binary_accuracy: 0.9680

Epoch 00012: val_loss did not improve from 0.09164047
Epoch 13/100
 - 6855s - loss: 0.0930 - binary_accuracy: 0.9683 - val_loss: 0.0903 - val_binary_accuracy: 0.9697

Epoch 00013: val_loss improved from 0.09164047 to 0.09031358, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 14/100
 - 6885s - loss: 0.0925 - binary_accuracy: 0.9684 - val_loss: 0.0907 - val_binary_accuracy: 0.9693

Epoch 00014: val_loss did not improve from 0.09031358
Epoch 15/100
 - 7746s - loss: 0.0918 - binary_accuracy: 0.9688 - val_loss: 0.0929 - val_binary_accuracy: 0.9681

Epoch 00015: val_loss did not improve from 0.09031358
Epoch 16/100
 - 10233s - loss: 0.0915 - binary_accuracy: 0.9689 - val_loss: 0.0944 - val_binary_accuracy: 0.9686

Epoch 00016: val_loss did not improve from 0.09031358
Epoch 17/100
 - 9012s - loss: 0.0908 - binary_accuracy: 0.9690 - val_loss: 0.0886 - val_binary_accuracy: 0.9701

Epoch 00017: val_loss improved from 0.09031358 to 0.08861315, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 18/100
 - 8486s - loss: 0.0901 - binary_accuracy: 0.9692 - val_loss: 0.0894 - val_binary_accuracy: 0.9699

Epoch 00018: val_loss did not improve from 0.08861315
Epoch 19/100
 - 8561s - loss: 0.0897 - binary_accuracy: 0.9695 - val_loss: 0.0913 - val_binary_accuracy: 0.9687

Epoch 00019: val_loss did not improve from 0.08861315
Epoch 20/100
 - 9360s - loss: 0.0890 - binary_accuracy: 0.9697 - val_loss: 0.0955 - val_binary_accuracy: 0.9671

Epoch 00020: val_loss did not improve from 0.08861315
Epoch 21/100
 - 9207s - loss: 0.0887 - binary_accuracy: 0.9697 - val_loss: 0.0887 - val_binary_accuracy: 0.9700

Epoch 00021: val_loss did not improve from 0.08861315
Epoch 22/100
 - 10166s - loss: 0.0883 - binary_accuracy: 0.9699 - val_loss: 0.0893 - val_binary_accuracy: 0.9704

Epoch 00022: val_loss did not improve from 0.08861315

Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.99999974738e-06.
Epoch 23/100
 - 9429s - loss: 0.0847 - binary_accuracy: 0.9711 - val_loss: 0.0802 - val_binary_accuracy: 0.9727

Epoch 00023: val_loss improved from 0.08861315 to 0.08015614, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 24/100
 - 8876s - loss: 0.0838 - binary_accuracy: 0.9713 - val_loss: 0.0802 - val_binary_accuracy: 0.9728

Epoch 00024: val_loss did not improve from 0.08015614
Epoch 25/100
 - 7649s - loss: 0.0834 - binary_accuracy: 0.9715 - val_loss: 0.0798 - val_binary_accuracy: 0.9728

Epoch 00025: val_loss improved from 0.08015614 to 0.07980516, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 26/100
 - 7729s - loss: 0.0832 - binary_accuracy: 0.9717 - val_loss: 0.0795 - val_binary_accuracy: 0.9729

Epoch 00026: val_loss improved from 0.07980516 to 0.07946983, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 27/100
 - 7272s - loss: 0.0832 - binary_accuracy: 0.9716 - val_loss: 0.0798 - val_binary_accuracy: 0.9728

Epoch 00027: val_loss did not improve from 0.07946983
Epoch 28/100
 - 7282s - loss: 0.0827 - binary_accuracy: 0.9718 - val_loss: 0.0796 - val_binary_accuracy: 0.9729

Epoch 00028: val_loss did not improve from 0.07946983
Epoch 29/100
 - 7048s - loss: 0.0824 - binary_accuracy: 0.9719 - val_loss: 0.0791 - val_binary_accuracy: 0.9730

Epoch 00029: val_loss improved from 0.07946983 to 0.07913004, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 30/100
 - 6798s - loss: 0.0824 - binary_accuracy: 0.9718 - val_loss: 0.0792 - val_binary_accuracy: 0.9729

Epoch 00030: val_loss did not improve from 0.07913004
Epoch 31/100
 - 7113s - loss: 0.0822 - binary_accuracy: 0.9720 - val_loss: 0.0793 - val_binary_accuracy: 0.9729

Epoch 00031: val_loss did not improve from 0.07913004
Epoch 32/100
 - 6594s - loss: 0.0822 - binary_accuracy: 0.9720 - val_loss: 0.0795 - val_binary_accuracy: 0.9728

Epoch 00032: val_loss did not improve from 0.07913004
Epoch 33/100
 - 6844s - loss: 0.0819 - binary_accuracy: 0.9721 - val_loss: 0.0788 - val_binary_accuracy: 0.9730

Epoch 00033: val_loss improved from 0.07913004 to 0.07879893, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 34/100
 - 7104s - loss: 0.0817 - binary_accuracy: 0.9720 - val_loss: 0.0792 - val_binary_accuracy: 0.9728

Epoch 00034: val_loss did not improve from 0.07879893
Epoch 35/100
 - 6580s - loss: 0.0816 - binary_accuracy: 0.9720 - val_loss: 0.0794 - val_binary_accuracy: 0.9728

Epoch 00035: val_loss did not improve from 0.07879893
Epoch 36/100
 - 7343s - loss: 0.0815 - binary_accuracy: 0.9721 - val_loss: 0.0784 - val_binary_accuracy: 0.9732

Epoch 00036: val_loss improved from 0.07879893 to 0.07836846, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 37/100
 - 7272s - loss: 0.0814 - binary_accuracy: 0.9722 - val_loss: 0.0787 - val_binary_accuracy: 0.9730

Epoch 00037: val_loss did not improve from 0.07836846
Epoch 38/100
 - 6504s - loss: 0.0813 - binary_accuracy: 0.9722 - val_loss: 0.0785 - val_binary_accuracy: 0.9730

Epoch 00038: val_loss did not improve from 0.07836846
Epoch 39/100
 - 6270s - loss: 0.0814 - binary_accuracy: 0.9722 - val_loss: 0.0783 - val_binary_accuracy: 0.9732

Epoch 00039: val_loss improved from 0.07836846 to 0.07825557, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 40/100
 - 7374s - loss: 0.0811 - binary_accuracy: 0.9723 - val_loss: 0.0785 - val_binary_accuracy: 0.9730

Epoch 00040: val_loss did not improve from 0.07825557
Epoch 41/100
 - 7030s - loss: 0.0811 - binary_accuracy: 0.9723 - val_loss: 0.0783 - val_binary_accuracy: 0.9731

Epoch 00041: val_loss did not improve from 0.07825557
Epoch 42/100
 - 6890s - loss: 0.0809 - binary_accuracy: 0.9724 - val_loss: 0.0782 - val_binary_accuracy: 0.9731

Epoch 00042: val_loss improved from 0.07825557 to 0.07817137, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 43/100
 - 6800s - loss: 0.0809 - binary_accuracy: 0.9724 - val_loss: 0.0786 - val_binary_accuracy: 0.9732

Epoch 00043: val_loss did not improve from 0.07817137
Epoch 44/100
 - 7669s - loss: 0.0806 - binary_accuracy: 0.9725 - val_loss: 0.0787 - val_binary_accuracy: 0.9729

Epoch 00044: val_loss did not improve from 0.07817137

Epoch 00044: ReduceLROnPlateau reducing learning rate to 1e-06.
Epoch 45/100
 - 6773s - loss: 0.0802 - binary_accuracy: 0.9726 - val_loss: 0.0781 - val_binary_accuracy: 0.9731

Epoch 00045: val_loss improved from 0.07817137 to 0.07807019, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 46/100
 - 7317s - loss: 0.0802 - binary_accuracy: 0.9726 - val_loss: 0.0776 - val_binary_accuracy: 0.9733

Epoch 00046: val_loss improved from 0.07807019 to 0.07759323, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 47/100
 - 7258s - loss: 0.0801 - binary_accuracy: 0.9725 - val_loss: 0.0775 - val_binary_accuracy: 0.9734

Epoch 00047: val_loss improved from 0.07759323 to 0.07748592, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 48/100
 - 7011s - loss: 0.0801 - binary_accuracy: 0.9726 - val_loss: 0.0778 - val_binary_accuracy: 0.9733

Epoch 00048: val_loss did not improve from 0.07748592
Epoch 49/100


PS:

Read file <./cluster_err/ResNet18_KFold_3_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng07>
Subject: Job 46386071: <ResNet18_KFold_3> in cluster <rcc> Exited

Job <ResNet18_KFold_3> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Sun Jan  6 19:01:20 2019
Job was executed on host(s) <lng07>, in queue <normal>, as user <rs619065> in cluster <rcc> at Sun Jan  6 19:11:11 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Sun Jan  6 19:11:11 2019
Terminated at Sun Jan  6 23:17:34 2019
Results reported at Sun Jan  6 23:17:34 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 3
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   38570.05 sec.
    Max Memory :                                 61608 MB
    Average Memory :                             42699.50 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               18392.00 MB
    Max Swap :                                   -
    Max Processes :                              21
    Max Threads :                                474
    Run time :                                   14783 sec.
    Turnaround time :                            15374 sec.

The output (if any) follows:

Training model on 84510 samples, validate on 21167 samples
Epoch 1/100
Epoch 1/100 - 7450s - loss: 0.0795 - binary_accuracy: 0.9725 - val_loss: 0.0848 - val_binary_accuracy: 0.9710

Epoch 00001: val_loss did not improve from 0.07748592
Epoch 2/100
 - 6706s - loss: 0.0792 - binary_accuracy: 0.9725 - val_loss: 0.0832 - val_binary_accuracy: 0.9717

Epoch 00002: val_loss did not improve from 0.07748592
Epoch 3/100


PS:

Read file <./cluster_err/ResNet18_KFold_3_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng07>
Subject: Job 46386638: <ResNet18_KFold_3> in cluster <rcc> Exited

Job <ResNet18_KFold_3> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Sun Jan  6 23:18:00 2019
Job was executed on host(s) <lng07>, in queue <normal>, as user <rs619065> in cluster <rcc> at Sun Jan  6 23:21:59 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Sun Jan  6 23:21:59 2019
Terminated at Mon Jan  7 12:36:39 2019
Results reported at Mon Jan  7 12:36:39 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 3
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   130963.00 sec.
    Max Memory :                                 63793 MB
    Average Memory :                             51126.72 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               16207.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              21
    Max Threads :                                473
    Run time :                                   47680 sec.
    Turnaround time :                            47919 sec.

The output (if any) follows:

Training model on 84510 samples, validate on 21167 samples
Epoch 1/100
Epoch 1/100
 - 7221s - loss: 0.0770 - binary_accuracy: 0.9734 - val_loss: 0.0768 - val_binary_accuracy: 0.9735

Epoch 00001: val_loss improved from 0.07748592 to 0.07676107, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 2/100
 - 6893s - loss: 0.0768 - binary_accuracy: 0.9733 - val_loss: 0.0766 - val_binary_accuracy: 0.9736

Epoch 00002: val_loss improved from 0.07676107 to 0.07658341, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 3/100
 - 6493s - loss: 0.0767 - binary_accuracy: 0.9734 - val_loss: 0.0767 - val_binary_accuracy: 0.9734

Epoch 00003: val_loss did not improve from 0.07658341
Epoch 4/100
 - 6512s - loss: 0.0767 - binary_accuracy: 0.9735 - val_loss: 0.0763 - val_binary_accuracy: 0.9736

Epoch 00004: val_loss improved from 0.07658341 to 0.07633732, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 5/100
 - 6473s - loss: 0.0765 - binary_accuracy: 0.9735 - val_loss: 0.0762 - val_binary_accuracy: 0.9735

Epoch 00005: val_loss improved from 0.07633732 to 0.07621426, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 6/100
 - 6582s - loss: 0.0764 - binary_accuracy: 0.9736 - val_loss: 0.0759 - val_binary_accuracy: 0.9737

Epoch 00006: val_loss improved from 0.07621426 to 0.07588214, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_3.h5
Epoch 7/100
 - 6804s - loss: 0.0762 - binary_accuracy: 0.9736 - val_loss: 0.0761 - val_binary_accuracy: 0.9738

Epoch 00007: val_loss did not improve from 0.07588214
Epoch 8/100


PS:

Read file <./cluster_err/ResNet18_KFold_3_err.txt> for stderr output of this job.

