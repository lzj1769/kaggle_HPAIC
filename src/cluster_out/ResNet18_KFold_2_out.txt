Sender: LSF System <lsfadmin@lng04>
Subject: Job 46177947: <ResNet18_KFold_2> in cluster <rcc> Done

Job <ResNet18_KFold_2> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Tue Dec 11 17:02:59 2018
Job was executed on host(s) <lng04>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Tue Dec 11 17:13:05 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Tue Dec 11 17:13:05 2018
Terminated at Sat Dec 15 16:33:00 2018
Results reported at Sat Dec 15 16:33:00 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 2
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   978300.81 sec.
    Max Memory :                                 43394 MB
    Average Memory :                             38065.13 MB
    Total Requested Memory :                     120000.00 MB
    Delta Memory :                               76606.00 MB
    Max Swap :                                   4 MB
    Max Processes :                              42
    Max Threads :                                874
    Run time :                                   343195 sec.
    Turnaround time :                            343801 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 64)           0           res2a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           res3a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 256)          0           res4a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 512)          0           res5a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1472)         0           global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
                                                                 global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
fc1024_1 (Dense)                (None, 512)          754176      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1024_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc1024_2 (Dense)                (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc1024_2[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,639,644
Trainable params: 13,627,868
Non-trainable params: 11,776
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_26[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_27[0][0]              
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_9 (Add)                     (None, 256, 256, 64) 0           activation_28[0][0]              
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 256, 256, 64) 0           add_9[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_29[0][0]              
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_30[0][0]              
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_10 (Add)                    (None, 256, 256, 64) 0           activation_31[0][0]              
                                                                 activation_29[0][0]              
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 256, 256, 64) 0           add_10[0][0]                     
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_32[0][0]              
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_33[0][0]              
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_32[0][0]              
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_11 (Add)                    (None, 128, 128, 128 0           activation_34[0][0]              
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 128, 128, 128 0           add_11[0][0]                     
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_35[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_36[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_12 (Add)                    (None, 128, 128, 128 0           activation_37[0][0]              
                                                                 activation_35[0][0]              
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 128, 128, 128 0           add_12[0][0]                     
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_38[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_39[0][0]              
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_38[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_13 (Add)                    (None, 64, 64, 256)  0           activation_40[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 64, 64, 256)  0           add_13[0][0]                     
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_41[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_42[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_14 (Add)                    (None, 64, 64, 256)  0           activation_43[0][0]              
                                                                 activation_41[0][0]              
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 64, 64, 256)  0           add_14[0][0]                     
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_44[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_45[0][0]              
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_44[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_15 (Add)                    (None, 32, 32, 512)  0           activation_46[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 32, 32, 512)  0           add_15[0][0]                     
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_47[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_48[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_16 (Add)                    (None, 32, 32, 512)  0           activation_49[0][0]              
                                                                 activation_47[0][0]              
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 32, 32, 512)  0           add_16[0][0]                     
__________________________________________________________________________________________________
global_average_pooling2d_7 (Glo (None, 64)           0           res2a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_8 (Glo (None, 128)          0           res3a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_9 (Glo (None, 256)          0           res4a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_10 (Gl (None, 512)          0           res5a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_6 (Glo (None, 512)          0           activation_50[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 1472)         0           global_average_pooling2d_7[0][0] 
                                                                 global_average_pooling2d_8[0][0] 
                                                                 global_average_pooling2d_9[0][0] 
                                                                 global_average_pooling2d_10[0][0]
                                                                 global_average_pooling2d_6[0][0] 
__________________________________________________________________________________________________
fc1024_1 (Dense)                (None, 512)          754176      concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1024_1[0][0]                   
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc1024_2 (Dense)                (None, 512)          262656      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc1024_2[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_4[0][0]                  
==================================================================================================
Total params: 13,639,644
Trainable params: 13,627,868
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84511 samples, validate on 21166 samples
Epoch 1/100
 - 5450s - loss: 0.3240 - binary_accuracy: 0.8655 - val_loss: 0.1534 - val_binary_accuracy: 0.9489

Epoch 00001: val_loss improved from inf to 0.15340192, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 2/100
 - 5832s - loss: 0.1548 - binary_accuracy: 0.9504 - val_loss: 0.1470 - val_binary_accuracy: 0.9533

Epoch 00002: val_loss improved from 0.15340192 to 0.14704107, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 3/100
 - 6860s - loss: 0.1382 - binary_accuracy: 0.9545 - val_loss: 0.1248 - val_binary_accuracy: 0.9582

Epoch 00003: val_loss improved from 0.14704107 to 0.12476101, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 4/100
 - 8023s - loss: 0.1267 - binary_accuracy: 0.9580 - val_loss: 0.1154 - val_binary_accuracy: 0.9626

Epoch 00004: val_loss improved from 0.12476101 to 0.11540818, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 5/100
 - 8339s - loss: 0.1206 - binary_accuracy: 0.9599 - val_loss: 0.1288 - val_binary_accuracy: 0.9559

Epoch 00005: val_loss did not improve from 0.11540818
Epoch 6/100
 - 8796s - loss: 0.1168 - binary_accuracy: 0.9611 - val_loss: 0.1212 - val_binary_accuracy: 0.9589

Epoch 00006: val_loss did not improve from 0.11540818
Epoch 7/100
 - 8581s - loss: 0.1139 - binary_accuracy: 0.9619 - val_loss: 0.1150 - val_binary_accuracy: 0.9634

Epoch 00007: val_loss improved from 0.11540818 to 0.11497798, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 8/100
 - 8038s - loss: 0.1123 - binary_accuracy: 0.9622 - val_loss: 0.1179 - val_binary_accuracy: 0.9624

Epoch 00008: val_loss did not improve from 0.11497798
Epoch 9/100
 - 8538s - loss: 0.1104 - binary_accuracy: 0.9629 - val_loss: 0.1068 - val_binary_accuracy: 0.9648

Epoch 00009: val_loss improved from 0.11497798 to 0.10676104, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 10/100
 - 8212s - loss: 0.1084 - binary_accuracy: 0.9634 - val_loss: 0.1022 - val_binary_accuracy: 0.9657

Epoch 00010: val_loss improved from 0.10676104 to 0.10218809, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 11/100
 - 7541s - loss: 0.1074 - binary_accuracy: 0.9638 - val_loss: 0.1168 - val_binary_accuracy: 0.9620

Epoch 00011: val_loss did not improve from 0.10218809
Epoch 12/100
 - 6945s - loss: 0.1068 - binary_accuracy: 0.9640 - val_loss: 0.1096 - val_binary_accuracy: 0.9646

Epoch 00012: val_loss did not improve from 0.10218809
Epoch 13/100
 - 8744s - loss: 0.1061 - binary_accuracy: 0.9641 - val_loss: 0.1073 - val_binary_accuracy: 0.9665

Epoch 00013: val_loss did not improve from 0.10218809
Epoch 14/100
 - 6003s - loss: 0.1052 - binary_accuracy: 0.9644 - val_loss: 0.1300 - val_binary_accuracy: 0.9584

Epoch 00014: val_loss did not improve from 0.10218809
Epoch 15/100
 - 5475s - loss: 0.1043 - binary_accuracy: 0.9648 - val_loss: 0.1116 - val_binary_accuracy: 0.9633

Epoch 00015: val_loss did not improve from 0.10218809
Epoch 16/100
 - 13055s - loss: 0.1036 - binary_accuracy: 0.9650 - val_loss: 0.1007 - val_binary_accuracy: 0.9661

Epoch 00016: val_loss improved from 0.10218809 to 0.10066132, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 17/100
 - 7617s - loss: 0.1033 - binary_accuracy: 0.9653 - val_loss: 0.0997 - val_binary_accuracy: 0.9661

Epoch 00017: val_loss improved from 0.10066132 to 0.09967294, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 18/100
 - 5917s - loss: 0.1029 - binary_accuracy: 0.9654 - val_loss: 0.0995 - val_binary_accuracy: 0.9664

Epoch 00018: val_loss improved from 0.09967294 to 0.09945453, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 19/100
 - 6788s - loss: 0.1022 - binary_accuracy: 0.9656 - val_loss: 0.1005 - val_binary_accuracy: 0.9666

Epoch 00019: val_loss did not improve from 0.09945453
Epoch 20/100
 - 5730s - loss: 0.1019 - binary_accuracy: 0.9657 - val_loss: 0.0995 - val_binary_accuracy: 0.9660

Epoch 00020: val_loss did not improve from 0.09945453
Epoch 21/100
 - 9011s - loss: 0.1016 - binary_accuracy: 0.9659 - val_loss: 0.0962 - val_binary_accuracy: 0.9683

Epoch 00021: val_loss improved from 0.09945453 to 0.09615336, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 22/100
 - 5750s - loss: 0.1009 - binary_accuracy: 0.9661 - val_loss: 0.0962 - val_binary_accuracy: 0.9680

Epoch 00022: val_loss did not improve from 0.09615336
Epoch 23/100
 - 5491s - loss: 0.1005 - binary_accuracy: 0.9662 - val_loss: 0.1211 - val_binary_accuracy: 0.9645

Epoch 00023: val_loss did not improve from 0.09615336
Epoch 24/100
 - 8406s - loss: 0.1002 - binary_accuracy: 0.9664 - val_loss: 0.1030 - val_binary_accuracy: 0.9677

Epoch 00024: val_loss did not improve from 0.09615336
Epoch 25/100
 - 6172s - loss: 0.0996 - binary_accuracy: 0.9666 - val_loss: 0.0950 - val_binary_accuracy: 0.9677

Epoch 00025: val_loss improved from 0.09615336 to 0.09502543, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 26/100
 - 5360s - loss: 0.0996 - binary_accuracy: 0.9666 - val_loss: 0.1155 - val_binary_accuracy: 0.9623

Epoch 00026: val_loss did not improve from 0.09502543
Epoch 27/100
 - 6009s - loss: 0.0991 - binary_accuracy: 0.9667 - val_loss: 0.0932 - val_binary_accuracy: 0.9687

Epoch 00027: val_loss improved from 0.09502543 to 0.09321726, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 28/100
 - 6386s - loss: 0.0989 - binary_accuracy: 0.9669 - val_loss: 0.0928 - val_binary_accuracy: 0.9680

Epoch 00028: val_loss improved from 0.09321726 to 0.09283141, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 29/100
 - 6703s - loss: 0.0989 - binary_accuracy: 0.9669 - val_loss: 0.0995 - val_binary_accuracy: 0.9677

Epoch 00029: val_loss did not improve from 0.09283141
Epoch 30/100
 - 5667s - loss: 0.0983 - binary_accuracy: 0.9671 - val_loss: 0.0908 - val_binary_accuracy: 0.9695

Epoch 00030: val_loss improved from 0.09283141 to 0.09077467, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 31/100
 - 5422s - loss: 0.0983 - binary_accuracy: 0.9672 - val_loss: 0.1023 - val_binary_accuracy: 0.9669

Epoch 00031: val_loss did not improve from 0.09077467
Epoch 32/100
 - 5929s - loss: 0.0981 - binary_accuracy: 0.9672 - val_loss: 0.0985 - val_binary_accuracy: 0.9685

Epoch 00032: val_loss did not improve from 0.09077467
Epoch 33/100
 - 6118s - loss: 0.0978 - binary_accuracy: 0.9672 - val_loss: 0.1080 - val_binary_accuracy: 0.9654

Epoch 00033: val_loss did not improve from 0.09077467
Epoch 34/100
 - 15504s - loss: 0.0978 - binary_accuracy: 0.9673 - val_loss: 0.0957 - val_binary_accuracy: 0.9689

Epoch 00034: val_loss did not improve from 0.09077467
Epoch 35/100
 - 6798s - loss: 0.0974 - binary_accuracy: 0.9673 - val_loss: 0.0955 - val_binary_accuracy: 0.9686

Epoch 00035: val_loss did not improve from 0.09077467
Epoch 36/100
 - 6171s - loss: 0.0972 - binary_accuracy: 0.9675 - val_loss: 0.1026 - val_binary_accuracy: 0.9685

Epoch 00036: val_loss did not improve from 0.09077467
Epoch 37/100
 - 5537s - loss: 0.0967 - binary_accuracy: 0.9677 - val_loss: 0.0981 - val_binary_accuracy: 0.9689

Epoch 00037: val_loss did not improve from 0.09077467
Epoch 38/100
 - 6276s - loss: 0.0966 - binary_accuracy: 0.9676 - val_loss: 0.0977 - val_binary_accuracy: 0.9670

Epoch 00038: val_loss did not improve from 0.09077467
Epoch 39/100
 - 5663s - loss: 0.0962 - binary_accuracy: 0.9678 - val_loss: 0.0981 - val_binary_accuracy: 0.9679

Epoch 00039: val_loss did not improve from 0.09077467
Epoch 40/100
 - 5891s - loss: 0.0959 - binary_accuracy: 0.9678 - val_loss: 0.0971 - val_binary_accuracy: 0.9681

Epoch 00040: val_loss did not improve from 0.09077467
Epoch 41/100
 - 7169s - loss: 0.0958 - binary_accuracy: 0.9679 - val_loss: 0.0927 - val_binary_accuracy: 0.9699

Epoch 00041: val_loss did not improve from 0.09077467
Epoch 42/100
 - 5445s - loss: 0.0960 - binary_accuracy: 0.9678 - val_loss: 0.0942 - val_binary_accuracy: 0.9693

Epoch 00042: val_loss did not improve from 0.09077467
Epoch 43/100
 - 5526s - loss: 0.0956 - binary_accuracy: 0.9679 - val_loss: 0.0912 - val_binary_accuracy: 0.9705

Epoch 00043: val_loss did not improve from 0.09077467
Epoch 44/100
 - 5562s - loss: 0.0954 - binary_accuracy: 0.9681 - val_loss: 0.0922 - val_binary_accuracy: 0.9690

Epoch 00044: val_loss did not improve from 0.09077467
Epoch 45/100
 - 6055s - loss: 0.0953 - binary_accuracy: 0.9681 - val_loss: 0.0911 - val_binary_accuracy: 0.9694

Epoch 00045: val_loss did not improve from 0.09077467
Epoch 46/100
 - 6435s - loss: 0.0951 - binary_accuracy: 0.9681 - val_loss: 0.0955 - val_binary_accuracy: 0.9669

Epoch 00046: val_loss did not improve from 0.09077467
Epoch 47/100
 - 5397s - loss: 0.0951 - binary_accuracy: 0.9681 - val_loss: 0.0975 - val_binary_accuracy: 0.9696

Epoch 00047: val_loss did not improve from 0.09077467
Epoch 48/100
 - 5906s - loss: 0.0948 - binary_accuracy: 0.9684 - val_loss: 0.0989 - val_binary_accuracy: 0.9681

Epoch 00048: val_loss did not improve from 0.09077467
Epoch 49/100
 - 5365s - loss: 0.0946 - binary_accuracy: 0.9683 - val_loss: 0.0929 - val_binary_accuracy: 0.9700

Epoch 00049: val_loss did not improve from 0.09077467
Epoch 50/100
 - 5493s - loss: 0.0944 - binary_accuracy: 0.9684 - val_loss: 0.0927 - val_binary_accuracy: 0.9700

Epoch 00050: val_loss did not improve from 0.09077467
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
complete!!


PS:

Read file <./cluster_err/ResNet18_KFold_2_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng02>
Subject: Job 46227120: <ResNet18_KFold_2> in cluster <rcc> Exited

Job <ResNet18_KFold_2> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Tue Dec 18 19:13:09 2018
Job was executed on host(s) <lng02>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Tue Dec 18 19:41:59 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Tue Dec 18 19:41:59 2018
Terminated at Wed Dec 19 13:47:07 2018
Results reported at Wed Dec 19 13:47:07 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 2
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   248425.00 sec.
    Max Memory :                                 40806 MB
    Average Memory :                             35897.01 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               61594.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   65108 sec.
    Turnaround time :                            66838 sec.

The output (if any) follows:

Training model on 84511 samples, validate on 21166 samples
Epoch 1/100
 - 5289s - loss: 0.0955 - binary_accuracy: 0.9680 - val_loss: 0.0854 - val_binary_accuracy: 0.9712

Epoch 00001: val_loss improved from 0.09077467 to 0.08536219, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 2/100
 - 5420s - loss: 0.0947 - binary_accuracy: 0.9684 - val_loss: 0.0867 - val_binary_accuracy: 0.9711

Epoch 00002: val_loss did not improve from 0.08536219
Epoch 3/100
 - 5339s - loss: 0.0945 - binary_accuracy: 0.9683 - val_loss: 0.0853 - val_binary_accuracy: 0.9711

Epoch 00003: val_loss improved from 0.08536219 to 0.08534062, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 4/100
 - 5479s - loss: 0.0941 - binary_accuracy: 0.9685 - val_loss: 0.0849 - val_binary_accuracy: 0.9713

Epoch 00004: val_loss improved from 0.08534062 to 0.08489886, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 5/100
 - 5433s - loss: 0.0938 - binary_accuracy: 0.9685 - val_loss: 0.0856 - val_binary_accuracy: 0.9713

Epoch 00005: val_loss did not improve from 0.08489886
Epoch 6/100
 - 5270s - loss: 0.0937 - binary_accuracy: 0.9688 - val_loss: 0.0845 - val_binary_accuracy: 0.9715

Epoch 00006: val_loss improved from 0.08489886 to 0.08445213, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 7/100
 - 5430s - loss: 0.0937 - binary_accuracy: 0.9686 - val_loss: 0.0846 - val_binary_accuracy: 0.9714

Epoch 00007: val_loss did not improve from 0.08445213
Epoch 8/100
 - 5262s - loss: 0.0935 - binary_accuracy: 0.9688 - val_loss: 0.0843 - val_binary_accuracy: 0.9716

Epoch 00008: val_loss improved from 0.08445213 to 0.08430114, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 9/100
 - 5438s - loss: 0.0934 - binary_accuracy: 0.9688 - val_loss: 0.0848 - val_binary_accuracy: 0.9714

Epoch 00009: val_loss did not improve from 0.08430114
Epoch 10/100
 - 5324s - loss: 0.0932 - binary_accuracy: 0.9688 - val_loss: 0.0832 - val_binary_accuracy: 0.9717

Epoch 00010: val_loss improved from 0.08430114 to 0.08320222, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 11/100
 - 5472s - loss: 0.0933 - binary_accuracy: 0.9689 - val_loss: 0.0834 - val_binary_accuracy: 0.9717

Epoch 00011: val_loss did not improve from 0.08320222
Epoch 12/100
 - 5483s - loss: 0.0932 - binary_accuracy: 0.9687 - val_loss: 0.0830 - val_binary_accuracy: 0.9719

Epoch 00012: val_loss improved from 0.08320222 to 0.08304012, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 13/100


PS:

Read file <./cluster_err/ResNet18_KFold_2_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng08>
Subject: Job 46232800: <ResNet18_KFold_2> in cluster <rcc> Exited

Job <ResNet18_KFold_2> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 19 13:55:15 2018
Job was executed on host(s) <lng08>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 19 15:20:48 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 19 15:20:48 2018
Terminated at Thu Dec 20 01:32:26 2018
Results reported at Thu Dec 20 01:32:26 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 2
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   189884.67 sec.
    Max Memory :                                 43157 MB
    Average Memory :                             36889.12 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               59243.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   36698 sec.
    Turnaround time :                            41831 sec.

The output (if any) follows:

Training model on 84511 samples, validate on 21166 samples
Epoch 1/100
 - 3418s - loss: 0.0999 - binary_accuracy: 0.9662 - val_loss: 0.0861 - val_binary_accuracy: 0.9710

Epoch 00001: val_loss did not improve from 0.08304012
Epoch 2/100
 - 3492s - loss: 0.0874 - binary_accuracy: 0.9703 - val_loss: 0.0840 - val_binary_accuracy: 0.9715

Epoch 00002: val_loss did not improve from 0.08304012
Epoch 3/100
 - 3563s - loss: 0.0860 - binary_accuracy: 0.9707 - val_loss: 0.0869 - val_binary_accuracy: 0.9705

Epoch 00003: val_loss did not improve from 0.08304012
Epoch 4/100
 - 3554s - loss: 0.0855 - binary_accuracy: 0.9708 - val_loss: 0.0833 - val_binary_accuracy: 0.9717

Epoch 00004: val_loss did not improve from 0.08304012
Epoch 5/100
 - 3556s - loss: 0.0850 - binary_accuracy: 0.9710 - val_loss: 0.0831 - val_binary_accuracy: 0.9719

Epoch 00005: val_loss did not improve from 0.08304012
Epoch 6/100
 - 3615s - loss: 0.0846 - binary_accuracy: 0.9712 - val_loss: 0.0828 - val_binary_accuracy: 0.9718

Epoch 00006: val_loss improved from 0.08304012 to 0.08283107, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 7/100
 - 3725s - loss: 0.0842 - binary_accuracy: 0.9713 - val_loss: 0.0838 - val_binary_accuracy: 0.9719

Epoch 00007: val_loss did not improve from 0.08283107
Epoch 8/100
 - 3720s - loss: 0.0840 - binary_accuracy: 0.9714 - val_loss: 0.0827 - val_binary_accuracy: 0.9719

Epoch 00008: val_loss improved from 0.08283107 to 0.08269976, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 9/100
 - 3796s - loss: 0.0838 - binary_accuracy: 0.9714 - val_loss: 0.0823 - val_binary_accuracy: 0.9722

Epoch 00009: val_loss improved from 0.08269976 to 0.08228650, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 10/100
 - 4017s - loss: 0.0834 - binary_accuracy: 0.9715 - val_loss: 0.0834 - val_binary_accuracy: 0.9718

Epoch 00010: val_loss did not improve from 0.08228650
Epoch 11/100


PS:

Read file <./cluster_err/ResNet18_KFold_2_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng01>
Subject: Job 46239946: <ResNet18_KFold_2> in cluster <rcc> Exited

Job <ResNet18_KFold_2> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Thu Dec 20 10:46:15 2018
Job was executed on host(s) <lng01>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Thu Dec 20 16:58:15 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Thu Dec 20 16:58:15 2018
Terminated at Fri Dec 21 09:51:22 2018
Results reported at Fri Dec 21 09:51:22 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 2
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   150250.23 sec.
    Max Memory :                                 36822 MB
    Average Memory :                             29550.56 MB
    Total Requested Memory :                     60000.00 MB
    Delta Memory :                               23178.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              21
    Max Threads :                                473
    Run time :                                   60787 sec.
    Turnaround time :                            83107 sec.

The output (if any) follows:

Training model on 84511 samples, validate on 21166 samples
Epoch 1/10
 - 7081s - loss: 0.0865 - binary_accuracy: 0.9705 - val_loss: 0.1020 - val_binary_accuracy: 0.9652

Epoch 00001: val_loss did not improve from 0.08228650
Epoch 2/10
 - 7013s - loss: 0.0860 - binary_accuracy: 0.9707 - val_loss: 0.0890 - val_binary_accuracy: 0.9706

Epoch 00002: val_loss did not improve from 0.08228650
Epoch 3/10
 - 7151s - loss: 0.0856 - binary_accuracy: 0.9707 - val_loss: 0.0919 - val_binary_accuracy: 0.9687

Epoch 00003: val_loss did not improve from 0.08228650
Epoch 4/10
 - 6736s - loss: 0.0851 - binary_accuracy: 0.9710 - val_loss: 0.0988 - val_binary_accuracy: 0.9642

Epoch 00004: val_loss did not improve from 0.08228650
Epoch 5/10
 - 5190s - loss: 0.0848 - binary_accuracy: 0.9710 - val_loss: 0.0933 - val_binary_accuracy: 0.9678

Epoch 00005: val_loss did not improve from 0.08228650
Epoch 6/10
 - 6761s - loss: 0.0844 - binary_accuracy: 0.9712 - val_loss: 0.0899 - val_binary_accuracy: 0.9699

Epoch 00006: val_loss did not improve from 0.08228650
Epoch 7/10
 - 7078s - loss: 0.0842 - binary_accuracy: 0.9712 - val_loss: 0.0969 - val_binary_accuracy: 0.9681

Epoch 00007: val_loss did not improve from 0.08228650
Epoch 8/10
 - 6577s - loss: 0.0836 - binary_accuracy: 0.9714 - val_loss: 0.0843 - val_binary_accuracy: 0.9716

Epoch 00008: val_loss did not improve from 0.08228650
Epoch 9/10
 - 6700s - loss: 0.0836 - binary_accuracy: 0.9714 - val_loss: 0.0907 - val_binary_accuracy: 0.9691

Epoch 00009: val_loss did not improve from 0.08228650
Epoch 10/10


PS:

Read file <./cluster_err/ResNet18_KFold_2_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng08>
Subject: Job 46356130: <ResNet18_KFold_2> in cluster <rcc> Exited

Job <ResNet18_KFold_2> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Mon Dec 31 10:37:01 2018
Job was executed on host(s) <lng08>, in queue <normal>, as user <rs619065> in cluster <rcc> at Tue Jan  1 19:43:19 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Tue Jan  1 19:43:19 2019
Terminated at Fri Jan  4 12:32:28 2019
Results reported at Fri Jan  4 12:32:28 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 2
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   611766.00 sec.
    Max Memory :                                 36404 MB
    Average Memory :                             29204.84 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               43596.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              21
    Max Threads :                                474
    Run time :                                   233349 sec.
    Turnaround time :                            352527 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 512)          262656      global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc2[0][0]                        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,148,124
Trainable params: 13,136,348
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84511 samples, validate on 21166 samples
Epoch 1/100
 - 7112s - loss: 0.3236 - binary_accuracy: 0.8665 - val_loss: 0.1440 - val_binary_accuracy: 0.9538

Epoch 00001: val_loss improved from inf to 0.14399694, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 2/100
 - 6772s - loss: 0.1518 - binary_accuracy: 0.9509 - val_loss: 0.1997 - val_binary_accuracy: 0.9474

Epoch 00002: val_loss did not improve from 0.14399694
Epoch 3/100
 - 6694s - loss: 0.1328 - binary_accuracy: 0.9564 - val_loss: 0.1323 - val_binary_accuracy: 0.9573

Epoch 00003: val_loss improved from 0.14399694 to 0.13230015, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 4/100
 - 6692s - loss: 0.1227 - binary_accuracy: 0.9592 - val_loss: 0.1141 - val_binary_accuracy: 0.9626

Epoch 00004: val_loss improved from 0.13230015 to 0.11406792, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 5/100
 - 6500s - loss: 0.1165 - binary_accuracy: 0.9611 - val_loss: 0.1234 - val_binary_accuracy: 0.9580

Epoch 00005: val_loss did not improve from 0.11406792
Epoch 6/100
 - 6508s - loss: 0.1122 - binary_accuracy: 0.9624 - val_loss: 0.1093 - val_binary_accuracy: 0.9634

Epoch 00006: val_loss improved from 0.11406792 to 0.10933671, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 7/100
 - 6692s - loss: 0.1094 - binary_accuracy: 0.9632 - val_loss: 0.1059 - val_binary_accuracy: 0.9652

Epoch 00007: val_loss improved from 0.10933671 to 0.10594060, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 8/100
 - 7057s - loss: 0.1071 - binary_accuracy: 0.9640 - val_loss: 0.1005 - val_binary_accuracy: 0.9653

Epoch 00008: val_loss improved from 0.10594060 to 0.10051610, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 9/100
 - 5902s - loss: 0.1053 - binary_accuracy: 0.9646 - val_loss: 0.1018 - val_binary_accuracy: 0.9665

Epoch 00009: val_loss did not improve from 0.10051610
Epoch 10/100
 - 6020s - loss: 0.1039 - binary_accuracy: 0.9649 - val_loss: 0.0988 - val_binary_accuracy: 0.9669

Epoch 00010: val_loss improved from 0.10051610 to 0.09882708, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 11/100
 - 8044s - loss: 0.1029 - binary_accuracy: 0.9653 - val_loss: 0.1058 - val_binary_accuracy: 0.9649

Epoch 00011: val_loss did not improve from 0.09882708
Epoch 12/100
 - 7437s - loss: 0.1018 - binary_accuracy: 0.9657 - val_loss: 0.0963 - val_binary_accuracy: 0.9671

Epoch 00012: val_loss improved from 0.09882708 to 0.09632974, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 13/100
 - 6859s - loss: 0.1011 - binary_accuracy: 0.9660 - val_loss: 0.0980 - val_binary_accuracy: 0.9664

Epoch 00013: val_loss did not improve from 0.09632974
Epoch 14/100
 - 6580s - loss: 0.1002 - binary_accuracy: 0.9663 - val_loss: 0.0960 - val_binary_accuracy: 0.9678

Epoch 00014: val_loss improved from 0.09632974 to 0.09600366, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 15/100
 - 6472s - loss: 0.0996 - binary_accuracy: 0.9664 - val_loss: 0.0938 - val_binary_accuracy: 0.9680

Epoch 00015: val_loss improved from 0.09600366 to 0.09378994, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 16/100
 - 6495s - loss: 0.0988 - binary_accuracy: 0.9668 - val_loss: 0.0882 - val_binary_accuracy: 0.9702

Epoch 00016: val_loss improved from 0.09378994 to 0.08823320, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 17/100
 - 6720s - loss: 0.0980 - binary_accuracy: 0.9669 - val_loss: 0.0997 - val_binary_accuracy: 0.9656

Epoch 00017: val_loss did not improve from 0.08823320
Epoch 18/100
 - 6371s - loss: 0.0977 - binary_accuracy: 0.9671 - val_loss: 0.0959 - val_binary_accuracy: 0.9675

Epoch 00018: val_loss did not improve from 0.08823320
Epoch 19/100
 - 6400s - loss: 0.0972 - binary_accuracy: 0.9673 - val_loss: 0.0907 - val_binary_accuracy: 0.9694

Epoch 00019: val_loss did not improve from 0.08823320
Epoch 20/100
 - 6313s - loss: 0.0965 - binary_accuracy: 0.9675 - val_loss: 0.0932 - val_binary_accuracy: 0.9683

Epoch 00020: val_loss did not improve from 0.08823320
Epoch 21/100
 - 7756s - loss: 0.0963 - binary_accuracy: 0.9676 - val_loss: 0.0884 - val_binary_accuracy: 0.9702

Epoch 00021: val_loss did not improve from 0.08823320

Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.99999974738e-06.
Epoch 22/100
 - 6719s - loss: 0.0930 - binary_accuracy: 0.9686 - val_loss: 0.0826 - val_binary_accuracy: 0.9717

Epoch 00022: val_loss improved from 0.08823320 to 0.08263401, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 23/100
 - 6245s - loss: 0.0920 - binary_accuracy: 0.9691 - val_loss: 0.0826 - val_binary_accuracy: 0.9719

Epoch 00023: val_loss improved from 0.08263401 to 0.08257381, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 24/100
 - 6931s - loss: 0.0920 - binary_accuracy: 0.9691 - val_loss: 0.0827 - val_binary_accuracy: 0.9717

Epoch 00024: val_loss did not improve from 0.08257381
Epoch 25/100
 - 7501s - loss: 0.0916 - binary_accuracy: 0.9693 - val_loss: 0.0823 - val_binary_accuracy: 0.9719

Epoch 00025: val_loss improved from 0.08257381 to 0.08233432, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 26/100
 - 9190s - loss: 0.0913 - binary_accuracy: 0.9694 - val_loss: 0.0822 - val_binary_accuracy: 0.9718

Epoch 00026: val_loss improved from 0.08233432 to 0.08218102, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 27/100
 - 9546s - loss: 0.0911 - binary_accuracy: 0.9694 - val_loss: 0.0820 - val_binary_accuracy: 0.9720

Epoch 00027: val_loss improved from 0.08218102 to 0.08200095, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 28/100
 - 8671s - loss: 0.0909 - binary_accuracy: 0.9695 - val_loss: 0.0817 - val_binary_accuracy: 0.9722

Epoch 00028: val_loss improved from 0.08200095 to 0.08166549, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 29/100
 - 8437s - loss: 0.0908 - binary_accuracy: 0.9695 - val_loss: 0.0817 - val_binary_accuracy: 0.9722

Epoch 00029: val_loss did not improve from 0.08166549
Epoch 30/100
 - 8629s - loss: 0.0908 - binary_accuracy: 0.9696 - val_loss: 0.0821 - val_binary_accuracy: 0.9720

Epoch 00030: val_loss did not improve from 0.08166549
Epoch 31/100
 - 9805s - loss: 0.0906 - binary_accuracy: 0.9696 - val_loss: 0.0814 - val_binary_accuracy: 0.9721

Epoch 00031: val_loss improved from 0.08166549 to 0.08136878, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 32/100
 - 9820s - loss: 0.0904 - binary_accuracy: 0.9696 - val_loss: 0.0811 - val_binary_accuracy: 0.9723

Epoch 00032: val_loss improved from 0.08136878 to 0.08106643, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 33/100


PS:

Read file <./cluster_err/ResNet18_KFold_2_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng04>
Subject: Job 46386070: <ResNet18_KFold_2> in cluster <rcc> Exited

Job <ResNet18_KFold_2> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Sun Jan  6 19:01:20 2019
Job was executed on host(s) <lng04>, in queue <normal>, as user <rs619065> in cluster <rcc> at Sun Jan  6 19:02:57 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Sun Jan  6 19:02:57 2019
Terminated at Sun Jan  6 23:17:34 2019
Results reported at Sun Jan  6 23:17:34 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 2
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   40757.36 sec.
    Max Memory :                                 64076 MB
    Average Memory :                             43153.31 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               15924.00 MB
    Max Swap :                                   -
    Max Processes :                              21
    Max Threads :                                473
    Run time :                                   15277 sec.
    Turnaround time :                            15374 sec.

The output (if any) follows:

Training model on 84511 samples, validate on 21166 samples
Epoch 1/100
 - 7304s - loss: 0.0843 - binary_accuracy: 0.9710 - val_loss: 0.0889 - val_binary_accuracy: 0.9695

Epoch 00001: val_loss did not improve from 0.08106643
Epoch 2/100
 - 6810s - loss: 0.0837 - binary_accuracy: 0.9710 - val_loss: 0.0829 - val_binary_accuracy: 0.9717

Epoch 00002: val_loss did not improve from 0.08106643
Epoch 3/100


PS:

Read file <./cluster_err/ResNet18_KFold_2_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng06>
Subject: Job 46386637: <ResNet18_KFold_2> in cluster <rcc> Exited

Job <ResNet18_KFold_2> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Sun Jan  6 23:17:59 2019
Job was executed on host(s) <lng06>, in queue <normal>, as user <rs619065> in cluster <rcc> at Sun Jan  6 23:21:55 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Sun Jan  6 23:21:55 2019
Terminated at Tue Jan  8 17:59:03 2019
Results reported at Tue Jan  8 17:59:03 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 2
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   401839.66 sec.
    Max Memory :                                 65748 MB
    Average Memory :                             55102.41 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               14252.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              21
    Max Threads :                                473
    Run time :                                   153428 sec.
    Turnaround time :                            153664 sec.

The output (if any) follows:

Training model on 84511 samples, validate on 21166 samples
Epoch 1/100
Epoch 1/100
 - 7000s - loss: 0.0819 - binary_accuracy: 0.9719 - val_loss: 0.0797 - val_binary_accuracy: 0.9727

Epoch 00001: val_loss improved from 0.08106643 to 0.07965721, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 2/100
 - 6760s - loss: 0.0816 - binary_accuracy: 0.9719 - val_loss: 0.0797 - val_binary_accuracy: 0.9727

Epoch 00002: val_loss did not improve from 0.07965721
Epoch 3/100
 - 6261s - loss: 0.0815 - binary_accuracy: 0.9719 - val_loss: 0.0793 - val_binary_accuracy: 0.9727

Epoch 00003: val_loss improved from 0.07965721 to 0.07931380, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 4/100
 - 6292s - loss: 0.0813 - binary_accuracy: 0.9720 - val_loss: 0.0794 - val_binary_accuracy: 0.9727

Epoch 00004: val_loss did not improve from 0.07931380
Epoch 5/100
 - 6157s - loss: 0.0810 - binary_accuracy: 0.9722 - val_loss: 0.0790 - val_binary_accuracy: 0.9729

Epoch 00005: val_loss improved from 0.07931380 to 0.07903555, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 6/100
 - 6426s - loss: 0.0810 - binary_accuracy: 0.9722 - val_loss: 0.0792 - val_binary_accuracy: 0.9728

Epoch 00006: val_loss did not improve from 0.07903555
Epoch 7/100
 - 6591s - loss: 0.0808 - binary_accuracy: 0.9721 - val_loss: 0.0794 - val_binary_accuracy: 0.9727

Epoch 00007: val_loss did not improve from 0.07903555
Epoch 8/100
 - 6179s - loss: 0.0807 - binary_accuracy: 0.9723 - val_loss: 0.0787 - val_binary_accuracy: 0.9729

Epoch 00008: val_loss improved from 0.07903555 to 0.07874792, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 9/100
 - 6719s - loss: 0.0805 - binary_accuracy: 0.9724 - val_loss: 0.0788 - val_binary_accuracy: 0.9729

Epoch 00009: val_loss did not improve from 0.07874792
Epoch 10/100
 - 6910s - loss: 0.0805 - binary_accuracy: 0.9723 - val_loss: 0.0789 - val_binary_accuracy: 0.9728

Epoch 00010: val_loss did not improve from 0.07874792
Epoch 11/100
 - 7050s - loss: 0.0802 - binary_accuracy: 0.9724 - val_loss: 0.0788 - val_binary_accuracy: 0.9729

Epoch 00011: val_loss did not improve from 0.07874792
Epoch 12/100
 - 7008s - loss: 0.0802 - binary_accuracy: 0.9724 - val_loss: 0.0789 - val_binary_accuracy: 0.9729

Epoch 00012: val_loss did not improve from 0.07874792
Epoch 13/100
 - 6755s - loss: 0.0801 - binary_accuracy: 0.9724 - val_loss: 0.0786 - val_binary_accuracy: 0.9730

Epoch 00013: val_loss improved from 0.07874792 to 0.07864543, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 14/100
 - 6750s - loss: 0.0800 - binary_accuracy: 0.9725 - val_loss: 0.0785 - val_binary_accuracy: 0.9730

Epoch 00014: val_loss improved from 0.07864543 to 0.07854088, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 15/100
 - 6723s - loss: 0.0798 - binary_accuracy: 0.9725 - val_loss: 0.0785 - val_binary_accuracy: 0.9729

Epoch 00015: val_loss improved from 0.07854088 to 0.07852550, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 16/100
 - 6469s - loss: 0.0798 - binary_accuracy: 0.9725 - val_loss: 0.0784 - val_binary_accuracy: 0.9731

Epoch 00016: val_loss improved from 0.07852550 to 0.07840409, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 17/100
 - 6646s - loss: 0.0797 - binary_accuracy: 0.9726 - val_loss: 0.0782 - val_binary_accuracy: 0.9730

Epoch 00017: val_loss improved from 0.07840409 to 0.07815300, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 18/100
 - 6631s - loss: 0.0795 - binary_accuracy: 0.9726 - val_loss: 0.0781 - val_binary_accuracy: 0.9730

Epoch 00018: val_loss improved from 0.07815300 to 0.07810662, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 19/100
 - 6524s - loss: 0.0793 - binary_accuracy: 0.9727 - val_loss: 0.0780 - val_binary_accuracy: 0.9730

Epoch 00019: val_loss improved from 0.07810662 to 0.07802063, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 20/100
 - 6761s - loss: 0.0794 - binary_accuracy: 0.9726 - val_loss: 0.0779 - val_binary_accuracy: 0.9732

Epoch 00020: val_loss improved from 0.07802063 to 0.07792059, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 21/100
 - 6864s - loss: 0.0792 - binary_accuracy: 0.9728 - val_loss: 0.0778 - val_binary_accuracy: 0.9732

Epoch 00021: val_loss improved from 0.07792059 to 0.07779770, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_2.h5
Epoch 22/100
 - 6962s - loss: 0.0791 - binary_accuracy: 0.9727 - val_loss: 0.0781 - val_binary_accuracy: 0.9731

Epoch 00022: val_loss did not improve from 0.07779770
Epoch 23/100
 - 6674s - loss: 0.0790 - binary_accuracy: 0.9728 - val_loss: 0.0781 - val_binary_accuracy: 0.9730

Epoch 00023: val_loss did not improve from 0.07779770
Epoch 24/100


PS:

Read file <./cluster_err/ResNet18_KFold_2_err.txt> for stderr output of this job.

