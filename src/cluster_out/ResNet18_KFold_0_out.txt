Sender: LSF System <lsfadmin@lng02>
Subject: Job 46183927: <ResNet18_KFold_0> in cluster <rcc> Exited

Job <ResNet18_KFold_0> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 12 00:10:05 2018
Job was executed on host(s) <lng02>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 12 00:38:25 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 12 00:38:25 2018
Terminated at Sun Dec 16 13:09:52 2018
Results reported at Sun Dec 16 13:09:52 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 0
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   1124244.00 sec.
    Max Memory :                                 42196 MB
    Average Memory :                             36603.29 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               60204.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   390687 sec.
    Turnaround time :                            392387 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 64)           0           res2a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           res3a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 256)          0           res4a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 512)          0           res5a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1472)         0           global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
                                                                 global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 512)          754176      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc2[0][0]                        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,639,644
Trainable params: 13,627,868
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84569 samples, validate on 21108 samples
Epoch 1/100
 - 8195s - loss: 0.3226 - binary_accuracy: 0.8653 - val_loss: 0.1522 - val_binary_accuracy: 0.9540

Epoch 00001: val_loss improved from inf to 0.15219759, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 2/100
 - 8178s - loss: 0.1526 - binary_accuracy: 0.9508 - val_loss: 0.1320 - val_binary_accuracy: 0.9569

Epoch 00002: val_loss improved from 0.15219759 to 0.13197334, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 3/100
 - 8630s - loss: 0.1348 - binary_accuracy: 0.9557 - val_loss: 0.1235 - val_binary_accuracy: 0.9591

Epoch 00003: val_loss improved from 0.13197334 to 0.12353004, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 4/100
 - 8099s - loss: 0.1260 - binary_accuracy: 0.9584 - val_loss: 0.1245 - val_binary_accuracy: 0.9588

Epoch 00004: val_loss did not improve from 0.12353004
Epoch 5/100
 - 8319s - loss: 0.1211 - binary_accuracy: 0.9598 - val_loss: 0.1424 - val_binary_accuracy: 0.9521

Epoch 00005: val_loss did not improve from 0.12353004
Epoch 6/100
 - 8851s - loss: 0.1168 - binary_accuracy: 0.9609 - val_loss: 0.1125 - val_binary_accuracy: 0.9619

Epoch 00006: val_loss improved from 0.12353004 to 0.11250669, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 7/100
 - 8556s - loss: 0.1141 - binary_accuracy: 0.9619 - val_loss: 0.1079 - val_binary_accuracy: 0.9649

Epoch 00007: val_loss improved from 0.11250669 to 0.10790644, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 8/100
 - 9768s - loss: 0.1120 - binary_accuracy: 0.9626 - val_loss: 0.1180 - val_binary_accuracy: 0.9631

Epoch 00008: val_loss did not improve from 0.10790644
Epoch 9/100
 - 7211s - loss: 0.1105 - binary_accuracy: 0.9629 - val_loss: 0.1093 - val_binary_accuracy: 0.9644

Epoch 00009: val_loss did not improve from 0.10790644
Epoch 10/100
 - 7220s - loss: 0.1085 - binary_accuracy: 0.9636 - val_loss: 0.1186 - val_binary_accuracy: 0.9617

Epoch 00010: val_loss did not improve from 0.10790644
Epoch 11/100
 - 7191s - loss: 0.1077 - binary_accuracy: 0.9638 - val_loss: 0.1014 - val_binary_accuracy: 0.9660

Epoch 00011: val_loss improved from 0.10790644 to 0.10137178, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 12/100
 - 5650s - loss: 0.1065 - binary_accuracy: 0.9641 - val_loss: 0.1006 - val_binary_accuracy: 0.9668

Epoch 00012: val_loss improved from 0.10137178 to 0.10060443, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 13/100
 - 8357s - loss: 0.1056 - binary_accuracy: 0.9645 - val_loss: 0.1056 - val_binary_accuracy: 0.9647

Epoch 00013: val_loss did not improve from 0.10060443
Epoch 14/100
 - 6990s - loss: 0.1051 - binary_accuracy: 0.9647 - val_loss: 0.1226 - val_binary_accuracy: 0.9586

Epoch 00014: val_loss did not improve from 0.10060443
Epoch 15/100
 - 6220s - loss: 0.1042 - binary_accuracy: 0.9650 - val_loss: 0.1091 - val_binary_accuracy: 0.9630

Epoch 00015: val_loss did not improve from 0.10060443
Epoch 16/100
 - 6630s - loss: 0.1037 - binary_accuracy: 0.9650 - val_loss: 0.1002 - val_binary_accuracy: 0.9673

Epoch 00016: val_loss improved from 0.10060443 to 0.10020427, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 17/100
 - 6907s - loss: 0.1033 - binary_accuracy: 0.9653 - val_loss: 0.1045 - val_binary_accuracy: 0.9653

Epoch 00017: val_loss did not improve from 0.10020427
Epoch 18/100
 - 5940s - loss: 0.1031 - binary_accuracy: 0.9654 - val_loss: 0.1352 - val_binary_accuracy: 0.9563

Epoch 00018: val_loss did not improve from 0.10020427
Epoch 19/100
 - 6744s - loss: 0.1024 - binary_accuracy: 0.9656 - val_loss: 0.1122 - val_binary_accuracy: 0.9649

Epoch 00019: val_loss did not improve from 0.10020427
Epoch 20/100
 - 6340s - loss: 0.1019 - binary_accuracy: 0.9657 - val_loss: 0.1028 - val_binary_accuracy: 0.9649

Epoch 00020: val_loss did not improve from 0.10020427
Epoch 21/100
 - 7912s - loss: 0.1016 - binary_accuracy: 0.9660 - val_loss: 0.0977 - val_binary_accuracy: 0.9674

Epoch 00021: val_loss improved from 0.10020427 to 0.09768406, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 22/100
 - 13316s - loss: 0.1013 - binary_accuracy: 0.9659 - val_loss: 0.0976 - val_binary_accuracy: 0.9677

Epoch 00022: val_loss improved from 0.09768406 to 0.09763705, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 23/100
 - 18635s - loss: 0.1011 - binary_accuracy: 0.9661 - val_loss: 0.0959 - val_binary_accuracy: 0.9684

Epoch 00023: val_loss improved from 0.09763705 to 0.09594593, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 24/100
 - 5660s - loss: 0.1008 - binary_accuracy: 0.9663 - val_loss: 0.0981 - val_binary_accuracy: 0.9671

Epoch 00024: val_loss did not improve from 0.09594593
Epoch 25/100
 - 6390s - loss: 0.1006 - binary_accuracy: 0.9663 - val_loss: 0.1022 - val_binary_accuracy: 0.9653

Epoch 00025: val_loss did not improve from 0.09594593
Epoch 26/100
 - 9555s - loss: 0.1003 - binary_accuracy: 0.9665 - val_loss: 0.0968 - val_binary_accuracy: 0.9680

Epoch 00026: val_loss did not improve from 0.09594593
Epoch 27/100
 - 5394s - loss: 0.1002 - binary_accuracy: 0.9664 - val_loss: 0.1033 - val_binary_accuracy: 0.9673

Epoch 00027: val_loss did not improve from 0.09594593
Epoch 28/100
 - 11590s - loss: 0.0995 - binary_accuracy: 0.9666 - val_loss: 0.0965 - val_binary_accuracy: 0.9675

Epoch 00028: val_loss did not improve from 0.09594593
Epoch 29/100
 - 8530s - loss: 0.0988 - binary_accuracy: 0.9669 - val_loss: 0.0992 - val_binary_accuracy: 0.9683

Epoch 00029: val_loss did not improve from 0.09594593
Epoch 30/100
 - 7695s - loss: 0.0986 - binary_accuracy: 0.9670 - val_loss: 0.0942 - val_binary_accuracy: 0.9678

Epoch 00030: val_loss improved from 0.09594593 to 0.09420910, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 31/100
 - 6561s - loss: 0.0987 - binary_accuracy: 0.9670 - val_loss: 0.0913 - val_binary_accuracy: 0.9691

Epoch 00031: val_loss improved from 0.09420910 to 0.09131143, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 32/100
 - 7242s - loss: 0.0983 - binary_accuracy: 0.9671 - val_loss: 0.0942 - val_binary_accuracy: 0.9687

Epoch 00032: val_loss did not improve from 0.09131143
Epoch 33/100
 - 6499s - loss: 0.0979 - binary_accuracy: 0.9672 - val_loss: 0.0959 - val_binary_accuracy: 0.9678

Epoch 00033: val_loss did not improve from 0.09131143
Epoch 34/100
 - 9134s - loss: 0.0982 - binary_accuracy: 0.9670 - val_loss: 0.0940 - val_binary_accuracy: 0.9693

Epoch 00034: val_loss did not improve from 0.09131143
Epoch 35/100
 - 11205s - loss: 0.0979 - binary_accuracy: 0.9673 - val_loss: 0.0960 - val_binary_accuracy: 0.9680

Epoch 00035: val_loss did not improve from 0.09131143
Epoch 36/100
 - 8071s - loss: 0.0979 - binary_accuracy: 0.9674 - val_loss: 0.0894 - val_binary_accuracy: 0.9701

Epoch 00036: val_loss improved from 0.09131143 to 0.08941636, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 37/100
 - 6969s - loss: 0.0976 - binary_accuracy: 0.9675 - val_loss: 0.0992 - val_binary_accuracy: 0.9651

Epoch 00037: val_loss did not improve from 0.08941636
Epoch 38/100
 - 6433s - loss: 0.0974 - binary_accuracy: 0.9675 - val_loss: 0.0916 - val_binary_accuracy: 0.9689

Epoch 00038: val_loss did not improve from 0.08941636
Epoch 39/100
 - 5506s - loss: 0.0973 - binary_accuracy: 0.9676 - val_loss: 0.0892 - val_binary_accuracy: 0.9699

Epoch 00039: val_loss improved from 0.08941636 to 0.08921562, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 40/100
 - 5401s - loss: 0.0972 - binary_accuracy: 0.9677 - val_loss: 0.0941 - val_binary_accuracy: 0.9698

Epoch 00040: val_loss did not improve from 0.08921562
Epoch 41/100
 - 5510s - loss: 0.0973 - binary_accuracy: 0.9675 - val_loss: 0.0961 - val_binary_accuracy: 0.9678

Epoch 00041: val_loss did not improve from 0.08921562
Epoch 42/100
 - 5238s - loss: 0.0972 - binary_accuracy: 0.9675 - val_loss: 0.0898 - val_binary_accuracy: 0.9703

Epoch 00042: val_loss did not improve from 0.08921562
Epoch 43/100
 - 5423s - loss: 0.0968 - binary_accuracy: 0.9678 - val_loss: 0.0962 - val_binary_accuracy: 0.9679

Epoch 00043: val_loss did not improve from 0.08921562
Epoch 44/100
 - 5531s - loss: 0.0968 - binary_accuracy: 0.9678 - val_loss: 0.0964 - val_binary_accuracy: 0.9696

Epoch 00044: val_loss did not improve from 0.08921562
Epoch 45/100
 - 5453s - loss: 0.0969 - binary_accuracy: 0.9677 - val_loss: 0.0884 - val_binary_accuracy: 0.9706

Epoch 00045: val_loss improved from 0.08921562 to 0.08835080, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 46/100
 - 5296s - loss: 0.0962 - binary_accuracy: 0.9679 - val_loss: 0.0911 - val_binary_accuracy: 0.9708

Epoch 00046: val_loss did not improve from 0.08835080
Epoch 47/100
 - 5441s - loss: 0.0965 - binary_accuracy: 0.9679 - val_loss: 0.0928 - val_binary_accuracy: 0.9683

Epoch 00047: val_loss did not improve from 0.08835080
Epoch 48/100
 - 5331s - loss: 0.0959 - binary_accuracy: 0.9680 - val_loss: 0.0942 - val_binary_accuracy: 0.9700

Epoch 00048: val_loss did not improve from 0.08835080
Epoch 49/100

Epoch 00048: val_loss did not improve from 0.08835080
 - 5297s - loss: 0.0960 - binary_accuracy: 0.9681 - val_loss: 0.0888 - val_binary_accuracy: 0.9708

Epoch 00049: val_loss did not improve from 0.08835080
Epoch 50/100
 - 5327s - loss: 0.0958 - binary_accuracy: 0.9681 - val_loss: 0.0913 - val_binary_accuracy: 0.9699

Epoch 00050: val_loss did not improve from 0.08835080
Epoch 51/100
 - 5387s - loss: 0.0960 - binary_accuracy: 0.9682 - val_loss: 0.1001 - val_binary_accuracy: 0.9683

Epoch 00051: val_loss did not improve from 0.08835080
Epoch 52/100
 - 5420s - loss: 0.0955 - binary_accuracy: 0.9682 - val_loss: 0.0893 - val_binary_accuracy: 0.9710

Epoch 00052: val_loss did not improve from 0.08835080
Epoch 53/100
 - 5337s - loss: 0.0962 - binary_accuracy: 0.9680 - val_loss: 0.1030 - val_binary_accuracy: 0.9689

Epoch 00053: val_loss did not improve from 0.08835080
Epoch 54/100


PS:

Read file <./cluster_err/ResNet18_KFold_0_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng05>
Subject: Job 46226569: <ResNet18_KFold_0> in cluster <rcc> Exited

Job <ResNet18_KFold_0> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Tue Dec 18 17:54:53 2018
Job was executed on host(s) <lng05>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Tue Dec 18 17:54:59 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Tue Dec 18 17:54:59 2018
Terminated at Wed Dec 19 13:51:07 2018
Results reported at Wed Dec 19 13:51:07 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 0
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   383139.22 sec.
    Max Memory :                                 42935 MB
    Average Memory :                             37190.29 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               59465.00 MB
    Max Swap :                                   4 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   71768 sec.
    Turnaround time :                            71774 sec.

The output (if any) follows:

Training model on 84569 samples, validate on 21108 samples
Epoch 1/100
 - 3561s - loss: 0.0939 - binary_accuracy: 0.9688 - val_loss: 0.0826 - val_binary_accuracy: 0.9723

Epoch 00001: val_loss improved from 0.08835080 to 0.08259422, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 2/100
 - 3352s - loss: 0.0932 - binary_accuracy: 0.9691 - val_loss: 0.0825 - val_binary_accuracy: 0.9724

Epoch 00002: val_loss improved from 0.08259422 to 0.08254456, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 3/100
 - 3679s - loss: 0.0929 - binary_accuracy: 0.9691 - val_loss: 0.0817 - val_binary_accuracy: 0.9726

Epoch 00003: val_loss improved from 0.08254456 to 0.08166523, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 4/100
 - 3596s - loss: 0.0926 - binary_accuracy: 0.9693 - val_loss: 0.0813 - val_binary_accuracy: 0.9726

Epoch 00004: val_loss improved from 0.08166523 to 0.08130612, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 5/100
 - 3636s - loss: 0.0925 - binary_accuracy: 0.9693 - val_loss: 0.0821 - val_binary_accuracy: 0.9725

Epoch 00005: val_loss did not improve from 0.08130612
Epoch 6/100
 - 3588s - loss: 0.0925 - binary_accuracy: 0.9694 - val_loss: 0.0814 - val_binary_accuracy: 0.9725

Epoch 00006: val_loss did not improve from 0.08130612
Epoch 7/100
 - 3427s - loss: 0.0923 - binary_accuracy: 0.9694 - val_loss: 0.0812 - val_binary_accuracy: 0.9727

Epoch 00007: val_loss improved from 0.08130612 to 0.08120850, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 8/100
 - 3493s - loss: 0.0921 - binary_accuracy: 0.9694 - val_loss: 0.0812 - val_binary_accuracy: 0.9724

Epoch 00008: val_loss improved from 0.08120850 to 0.08116565, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 9/100
 - 3465s - loss: 0.0921 - binary_accuracy: 0.9694 - val_loss: 0.0812 - val_binary_accuracy: 0.9726

Epoch 00009: val_loss did not improve from 0.08116565
Epoch 10/100
 - 3539s - loss: 0.0922 - binary_accuracy: 0.9694 - val_loss: 0.0813 - val_binary_accuracy: 0.9726

Epoch 00010: val_loss did not improve from 0.08116565
Epoch 11/100
 - 3579s - loss: 0.0919 - binary_accuracy: 0.9695 - val_loss: 0.0812 - val_binary_accuracy: 0.9726

Epoch 00011: val_loss did not improve from 0.08116565
Epoch 12/100
 - 3585s - loss: 0.0917 - binary_accuracy: 0.9694 - val_loss: 0.0814 - val_binary_accuracy: 0.9725

Epoch 00012: val_loss did not improve from 0.08116565
Epoch 13/100
 - 3479s - loss: 0.0917 - binary_accuracy: 0.9694 - val_loss: 0.0808 - val_binary_accuracy: 0.9726

Epoch 00013: val_loss improved from 0.08116565 to 0.08080245, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 14/100
 - 3520s - loss: 0.0916 - binary_accuracy: 0.9696 - val_loss: 0.0800 - val_binary_accuracy: 0.9730

Epoch 00014: val_loss improved from 0.08080245 to 0.08001021, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 15/100
 - 3482s - loss: 0.0916 - binary_accuracy: 0.9696 - val_loss: 0.0806 - val_binary_accuracy: 0.9727

Epoch 00015: val_loss did not improve from 0.08001021
Epoch 16/100
 - 3560s - loss: 0.0916 - binary_accuracy: 0.9696 - val_loss: 0.0806 - val_binary_accuracy: 0.9726

Epoch 00016: val_loss did not improve from 0.08001021
Epoch 17/100
 - 3877s - loss: 0.0913 - binary_accuracy: 0.9698 - val_loss: 0.0800 - val_binary_accuracy: 0.9730

Epoch 00017: val_loss improved from 0.08001021 to 0.07996703, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 18/100
 - 3763s - loss: 0.0914 - binary_accuracy: 0.9696 - val_loss: 0.0801 - val_binary_accuracy: 0.9728

Epoch 00018: val_loss did not improve from 0.07996703
Epoch 19/100
 - 3744s - loss: 0.0912 - binary_accuracy: 0.9697 - val_loss: 0.0807 - val_binary_accuracy: 0.9729

Epoch 00019: val_loss did not improve from 0.07996703
Epoch 20/100
 - 3576s - loss: 0.0911 - binary_accuracy: 0.9697 - val_loss: 0.0802 - val_binary_accuracy: 0.9729

Epoch 00020: val_loss did not improve from 0.07996703
Epoch 21/100


PS:

Read file <./cluster_err/ResNet18_KFold_0_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng03>
Subject: Job 46232791: <ResNet18_KFold_0> in cluster <rcc> Exited

Job <ResNet18_KFold_0> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 19 13:54:59 2018
Job was executed on host(s) <lng03>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 19 14:13:43 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 19 14:13:43 2018
Terminated at Thu Dec 20 18:54:36 2018
Results reported at Thu Dec 20 18:54:36 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 0
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   445225.41 sec.
    Max Memory :                                 43343 MB
    Average Memory :                             38820.54 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               59057.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              40
    Max Threads :                                873
    Run time :                                   103253 sec.
    Turnaround time :                            104377 sec.

The output (if any) follows:

Training model on 84569 samples, validate on 21108 samples
Epoch 1/100
 - 3371s - loss: 0.0826 - binary_accuracy: 0.9719 - val_loss: 0.0800 - val_binary_accuracy: 0.9728

Epoch 00001: val_loss did not improve from 0.07996703
Epoch 2/100
 - 3394s - loss: 0.0823 - binary_accuracy: 0.9720 - val_loss: 0.0802 - val_binary_accuracy: 0.9729

Epoch 00002: val_loss did not improve from 0.07996703
Epoch 3/100
 - 3478s - loss: 0.0821 - binary_accuracy: 0.9721 - val_loss: 0.0796 - val_binary_accuracy: 0.9730

Epoch 00003: val_loss improved from 0.07996703 to 0.07956182, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 4/100
 - 3575s - loss: 0.0816 - binary_accuracy: 0.9723 - val_loss: 0.0795 - val_binary_accuracy: 0.9731

Epoch 00004: val_loss improved from 0.07956182 to 0.07954727, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 5/100
 - 3534s - loss: 0.0816 - binary_accuracy: 0.9722 - val_loss: 0.0793 - val_binary_accuracy: 0.9730

Epoch 00005: val_loss improved from 0.07954727 to 0.07925631, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 6/100
 - 3565s - loss: 0.0815 - binary_accuracy: 0.9722 - val_loss: 0.0798 - val_binary_accuracy: 0.9728

Epoch 00006: val_loss did not improve from 0.07925631
Epoch 7/100
 - 3617s - loss: 0.0812 - binary_accuracy: 0.9724 - val_loss: 0.0793 - val_binary_accuracy: 0.9730

Epoch 00007: val_loss did not improve from 0.07925631
Epoch 8/100
 - 4074s - loss: 0.0812 - binary_accuracy: 0.9724 - val_loss: 0.0793 - val_binary_accuracy: 0.9729

Epoch 00008: val_loss did not improve from 0.07925631
Epoch 9/100
 - 5177s - loss: 0.0810 - binary_accuracy: 0.9725 - val_loss: 0.0784 - val_binary_accuracy: 0.9733

Epoch 00009: val_loss improved from 0.07925631 to 0.07839671, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 10/100
 - 5243s - loss: 0.0808 - binary_accuracy: 0.9725 - val_loss: 0.0792 - val_binary_accuracy: 0.9730

Epoch 00010: val_loss did not improve from 0.07839671
Epoch 11/100
 - 5240s - loss: 0.0806 - binary_accuracy: 0.9726 - val_loss: 0.0785 - val_binary_accuracy: 0.9733

Epoch 00011: val_loss did not improve from 0.07839671
Epoch 12/100
 - 5156s - loss: 0.0807 - binary_accuracy: 0.9726 - val_loss: 0.0784 - val_binary_accuracy: 0.9733

Epoch 00012: val_loss did not improve from 0.07839671
Epoch 13/100
 - 5328s - loss: 0.0805 - binary_accuracy: 0.9726 - val_loss: 0.0784 - val_binary_accuracy: 0.9733

Epoch 00013: val_loss did not improve from 0.07839671
Epoch 14/100
 - 5239s - loss: 0.0804 - binary_accuracy: 0.9727 - val_loss: 0.0787 - val_binary_accuracy: 0.9731

Epoch 00014: val_loss did not improve from 0.07839671
Epoch 15/100
 - 5417s - loss: 0.0803 - binary_accuracy: 0.9727 - val_loss: 0.0782 - val_binary_accuracy: 0.9732

Epoch 00015: val_loss improved from 0.07839671 to 0.07820999, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 16/100
 - 5272s - loss: 0.0804 - binary_accuracy: 0.9727 - val_loss: 0.0786 - val_binary_accuracy: 0.9732

Epoch 00016: val_loss did not improve from 0.07820999
Epoch 17/100
 - 5214s - loss: 0.0801 - binary_accuracy: 0.9728 - val_loss: 0.0785 - val_binary_accuracy: 0.9732

Epoch 00017: val_loss did not improve from 0.07820999
Epoch 18/100
 - 5310s - loss: 0.0800 - binary_accuracy: 0.9728 - val_loss: 0.0781 - val_binary_accuracy: 0.9733

Epoch 00018: val_loss improved from 0.07820999 to 0.07808566, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 19/100
 - 5238s - loss: 0.0798 - binary_accuracy: 0.9728 - val_loss: 0.0784 - val_binary_accuracy: 0.9732

Epoch 00019: val_loss did not improve from 0.07808566
Epoch 20/100
 - 5397s - loss: 0.0797 - binary_accuracy: 0.9728 - val_loss: 0.0785 - val_binary_accuracy: 0.9732

Epoch 00020: val_loss did not improve from 0.07808566
Epoch 21/100
 - 5262s - loss: 0.0797 - binary_accuracy: 0.9729 - val_loss: 0.0777 - val_binary_accuracy: 0.9734

Epoch 00021: val_loss improved from 0.07808566 to 0.07771133, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_0.h5
Epoch 22/100
 - 5486s - loss: 0.0796 - binary_accuracy: 0.9729 - val_loss: 0.0784 - val_binary_accuracy: 0.9733

Epoch 00022: val_loss did not improve from 0.07771133
Epoch 23/100


PS:

Read file <./cluster_err/ResNet18_KFold_0_err.txt> for stderr output of this job.

