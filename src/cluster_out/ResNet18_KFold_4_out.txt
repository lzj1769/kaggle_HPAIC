Sender: LSF System <lsfadmin@lng01>
Subject: Job 46184810: <ResNet18_KFold_4> in cluster <rcc> Exited

Job <ResNet18_KFold_4> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 12 01:29:51 2018
Job was executed on host(s) <lng01>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 12 12:43:17 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 12 12:43:17 2018
Terminated at Sun Dec 16 23:30:25 2018
Results reported at Sun Dec 16 23:30:25 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 4
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   1238258.00 sec.
    Max Memory :                                 43510 MB
    Average Memory :                             36467.83 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               58890.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   384428 sec.
    Turnaround time :                            424834 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 64)           0           res2a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           res3a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 256)          0           res4a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 512)          0           res5a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1472)         0           global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
                                                                 global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 512)          754176      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc2[0][0]                        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,639,644
Trainable params: 13,627,868
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84572 samples, validate on 21105 samples
Epoch 1/100
 - 9393s - loss: 0.3241 - binary_accuracy: 0.8659 - val_loss: 0.1510 - val_binary_accuracy: 0.9509

Epoch 00001: val_loss improved from inf to 0.15096711, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 2/100
 - 6711s - loss: 0.1517 - binary_accuracy: 0.9510 - val_loss: 0.1347 - val_binary_accuracy: 0.9548

Epoch 00002: val_loss improved from 0.15096711 to 0.13465303, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 3/100
 - 9079s - loss: 0.1340 - binary_accuracy: 0.9559 - val_loss: 0.1267 - val_binary_accuracy: 0.9585

Epoch 00003: val_loss improved from 0.13465303 to 0.12667723, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 4/100
 - 7286s - loss: 0.1254 - binary_accuracy: 0.9587 - val_loss: 0.1296 - val_binary_accuracy: 0.9581

Epoch 00004: val_loss did not improve from 0.12667723
Epoch 5/100
 - 6375s - loss: 0.1198 - binary_accuracy: 0.9602 - val_loss: 0.1404 - val_binary_accuracy: 0.9542

Epoch 00005: val_loss did not improve from 0.12667723
Epoch 6/100
 - 6140s - loss: 0.1156 - binary_accuracy: 0.9615 - val_loss: 0.1141 - val_binary_accuracy: 0.9604

Epoch 00006: val_loss improved from 0.12667723 to 0.11406037, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 7/100
 - 14707s - loss: 0.1131 - binary_accuracy: 0.9622 - val_loss: 0.1089 - val_binary_accuracy: 0.9639

Epoch 00007: val_loss improved from 0.11406037 to 0.10886899, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 8/100
 - 6015s - loss: 0.1109 - binary_accuracy: 0.9629 - val_loss: 0.1104 - val_binary_accuracy: 0.9629

Epoch 00008: val_loss did not improve from 0.10886899
Epoch 9/100
 - 7586s - loss: 0.1095 - binary_accuracy: 0.9631 - val_loss: 0.1201 - val_binary_accuracy: 0.9608

Epoch 00009: val_loss did not improve from 0.10886899
Epoch 10/100
 - 8089s - loss: 0.1082 - binary_accuracy: 0.9637 - val_loss: 0.1056 - val_binary_accuracy: 0.9660

Epoch 00010: val_loss improved from 0.10886899 to 0.10561146, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 11/100
 - 10502s - loss: 0.1073 - binary_accuracy: 0.9640 - val_loss: 0.1097 - val_binary_accuracy: 0.9652

Epoch 00011: val_loss did not improve from 0.10561146
Epoch 12/100
 - 7836s - loss: 0.1064 - binary_accuracy: 0.9643 - val_loss: 0.1082 - val_binary_accuracy: 0.9646

Epoch 00012: val_loss did not improve from 0.10561146
Epoch 13/100
 - 7200s - loss: 0.1058 - binary_accuracy: 0.9645 - val_loss: 0.1015 - val_binary_accuracy: 0.9653

Epoch 00013: val_loss improved from 0.10561146 to 0.10150617, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 14/100
 - 6025s - loss: 0.1051 - binary_accuracy: 0.9646 - val_loss: 0.1092 - val_binary_accuracy: 0.9661

Epoch 00014: val_loss did not improve from 0.10150617
Epoch 15/100
 - 5739s - loss: 0.1042 - binary_accuracy: 0.9650 - val_loss: 0.1015 - val_binary_accuracy: 0.9675

Epoch 00015: val_loss improved from 0.10150617 to 0.10149643, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 16/100
 - 5830s - loss: 0.1037 - binary_accuracy: 0.9652 - val_loss: 0.1183 - val_binary_accuracy: 0.9658

Epoch 00016: val_loss did not improve from 0.10149643
Epoch 17/100
 - 6396s - loss: 0.1030 - binary_accuracy: 0.9653 - val_loss: 0.1038 - val_binary_accuracy: 0.9658

Epoch 00017: val_loss did not improve from 0.10149643
Epoch 18/100
 - 6773s - loss: 0.1029 - binary_accuracy: 0.9654 - val_loss: 0.0999 - val_binary_accuracy: 0.9669

Epoch 00018: val_loss improved from 0.10149643 to 0.09985256, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 19/100
 - 5699s - loss: 0.1025 - binary_accuracy: 0.9656 - val_loss: 0.0986 - val_binary_accuracy: 0.9675

Epoch 00019: val_loss improved from 0.09985256 to 0.09856923, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 20/100
 - 6129s - loss: 0.1027 - binary_accuracy: 0.9656 - val_loss: 0.0950 - val_binary_accuracy: 0.9679

Epoch 00020: val_loss improved from 0.09856923 to 0.09502716, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 21/100
 - 5858s - loss: 0.1021 - binary_accuracy: 0.9658 - val_loss: 0.0952 - val_binary_accuracy: 0.9673

Epoch 00021: val_loss did not improve from 0.09502716
Epoch 22/100
 - 5962s - loss: 0.1016 - binary_accuracy: 0.9659 - val_loss: 0.0978 - val_binary_accuracy: 0.9664

Epoch 00022: val_loss did not improve from 0.09502716
Epoch 23/100
 - 16929s - loss: 0.1016 - binary_accuracy: 0.9660 - val_loss: 0.0987 - val_binary_accuracy: 0.9678

Epoch 00023: val_loss did not improve from 0.09502716
Epoch 24/100
 - 7098s - loss: 0.1011 - binary_accuracy: 0.9662 - val_loss: 0.1001 - val_binary_accuracy: 0.9671

Epoch 00024: val_loss did not improve from 0.09502716
Epoch 25/100
 - 6273s - loss: 0.1008 - binary_accuracy: 0.9663 - val_loss: 0.0978 - val_binary_accuracy: 0.9660

Epoch 00025: val_loss did not improve from 0.09502716
Epoch 26/100
 - 6237s - loss: 0.1003 - binary_accuracy: 0.9665 - val_loss: 0.0929 - val_binary_accuracy: 0.9683

Epoch 00026: val_loss improved from 0.09502716 to 0.09292017, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 27/100
 - 6480s - loss: 0.1000 - binary_accuracy: 0.9665 - val_loss: 0.0951 - val_binary_accuracy: 0.9685

Epoch 00027: val_loss did not improve from 0.09292017
Epoch 28/100
 - 5573s - loss: 0.0995 - binary_accuracy: 0.9667 - val_loss: 0.1131 - val_binary_accuracy: 0.9667

Epoch 00028: val_loss did not improve from 0.09292017
Epoch 29/100
 - 5424s - loss: 0.0995 - binary_accuracy: 0.9667 - val_loss: 0.1022 - val_binary_accuracy: 0.9672

Epoch 00029: val_loss did not improve from 0.09292017
Epoch 30/100
 - 5894s - loss: 0.0990 - binary_accuracy: 0.9669 - val_loss: 0.0973 - val_binary_accuracy: 0.9685

Epoch 00030: val_loss did not improve from 0.09292017
Epoch 31/100
 - 5414s - loss: 0.0984 - binary_accuracy: 0.9670 - val_loss: 0.0920 - val_binary_accuracy: 0.9692

Epoch 00031: val_loss improved from 0.09292017 to 0.09204583, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 32/100
 - 5660s - loss: 0.0979 - binary_accuracy: 0.9673 - val_loss: 0.0917 - val_binary_accuracy: 0.9692

Epoch 00032: val_loss improved from 0.09204583 to 0.09166098, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 33/100
 - 5577s - loss: 0.0978 - binary_accuracy: 0.9672 - val_loss: 0.0953 - val_binary_accuracy: 0.9685

Epoch 00033: val_loss did not improve from 0.09166098
Epoch 34/100
 - 5455s - loss: 0.0972 - binary_accuracy: 0.9676 - val_loss: 0.0905 - val_binary_accuracy: 0.9699

Epoch 00034: val_loss improved from 0.09166098 to 0.09052240, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 35/100
 - 6116s - loss: 0.0967 - binary_accuracy: 0.9677 - val_loss: 0.1030 - val_binary_accuracy: 0.9673

Epoch 00035: val_loss did not improve from 0.09052240
Epoch 36/100
 - 5816s - loss: 0.0970 - binary_accuracy: 0.9676 - val_loss: 0.0918 - val_binary_accuracy: 0.9694

Epoch 00036: val_loss did not improve from 0.09052240
Epoch 37/100
 - 6177s - loss: 0.0967 - binary_accuracy: 0.9676 - val_loss: 0.0907 - val_binary_accuracy: 0.9692

Epoch 00037: val_loss did not improve from 0.09052240
Epoch 38/100
 - 5400s - loss: 0.0968 - binary_accuracy: 0.9677 - val_loss: 0.0940 - val_binary_accuracy: 0.9693

Epoch 00038: val_loss did not improve from 0.09052240
Epoch 39/100
 - 5445s - loss: 0.0966 - binary_accuracy: 0.9677 - val_loss: 0.1119 - val_binary_accuracy: 0.9665

Epoch 00039: val_loss did not improve from 0.09052240
Epoch 40/100
 - 5429s - loss: 0.0965 - binary_accuracy: 0.9679 - val_loss: 0.1092 - val_binary_accuracy: 0.9666

Epoch 00040: val_loss did not improve from 0.09052240
Epoch 41/100
 - 5552s - loss: 0.0962 - binary_accuracy: 0.9678 - val_loss: 0.0948 - val_binary_accuracy: 0.9688

Epoch 00041: val_loss did not improve from 0.09052240
Epoch 42/100
 - 5333s - loss: 0.0961 - binary_accuracy: 0.9679 - val_loss: 0.0988 - val_binary_accuracy: 0.9685

Epoch 00042: val_loss did not improve from 0.09052240
Epoch 43/100
 - 5409s - loss: 0.0959 - binary_accuracy: 0.9680 - val_loss: 0.0915 - val_binary_accuracy: 0.9694

Epoch 00043: val_loss did not improve from 0.09052240
Epoch 44/100
 - 5531s - loss: 0.0959 - binary_accuracy: 0.9680 - val_loss: 0.0889 - val_binary_accuracy: 0.9703

Epoch 00044: val_loss improved from 0.09052240 to 0.08894814, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 45/100
 - 5435s - loss: 0.0957 - binary_accuracy: 0.9681 - val_loss: 0.0935 - val_binary_accuracy: 0.9689

Epoch 00045: val_loss did not improve from 0.08894814
Epoch 46/100
 - 5600s - loss: 0.0954 - binary_accuracy: 0.9682 - val_loss: 0.1192 - val_binary_accuracy: 0.9662

Epoch 00046: val_loss did not improve from 0.08894814
Epoch 47/100
 - 5325s - loss: 0.0954 - binary_accuracy: 0.9682 - val_loss: 0.0932 - val_binary_accuracy: 0.9692

Epoch 00047: val_loss did not improve from 0.08894814
Epoch 48/100
 - 5443s - loss: 0.0953 - binary_accuracy: 0.9682 - val_loss: 0.1010 - val_binary_accuracy: 0.9655

Epoch 00048: val_loss did not improve from 0.08894814
Epoch 49/100
 - 5441s - loss: 0.0951 - binary_accuracy: 0.9683 - val_loss: 0.0978 - val_binary_accuracy: 0.9693

Epoch 00049: val_loss did not improve from 0.08894814
Epoch 50/100
 - 5241s - loss: 0.0951 - binary_accuracy: 0.9683 - val_loss: 0.1067 - val_binary_accuracy: 0.9678

Epoch 00050: val_loss did not improve from 0.08894814
Epoch 51/100
 - 5388s - loss: 0.0948 - binary_accuracy: 0.9684 - val_loss: 0.1005 - val_binary_accuracy: 0.9694

Epoch 00051: val_loss did not improve from 0.08894814
Epoch 52/100
 - 5440s - loss: 0.0947 - binary_accuracy: 0.9686 - val_loss: 0.1019 - val_binary_accuracy: 0.9694

Epoch 00052: val_loss did not improve from 0.08894814
Epoch 53/100
 - 5667s - loss: 0.0946 - binary_accuracy: 0.9686 - val_loss: 0.1082 - val_binary_accuracy: 0.9691

Epoch 00053: val_loss did not improve from 0.08894814
Epoch 54/100

Epoch 00053: val_loss did not improve from 0.08894814
 - 5781s - loss: 0.0945 - binary_accuracy: 0.9685 - val_loss: 0.1089 - val_binary_accuracy: 0.9673

Epoch 00054: val_loss did not improve from 0.08894814
Epoch 55/100
 - 5362s - loss: 0.0945 - binary_accuracy: 0.9685 - val_loss: 0.0969 - val_binary_accuracy: 0.9700

Epoch 00055: val_loss did not improve from 0.08894814
Epoch 56/100
 - 5193s - loss: 0.0943 - binary_accuracy: 0.9686 - val_loss: 0.1044 - val_binary_accuracy: 0.9682

Epoch 00056: val_loss did not improve from 0.08894814
Epoch 57/100

Epoch 00056: val_loss did not improve from 0.08894814
 - 5498s - loss: 0.0943 - binary_accuracy: 0.9686 - val_loss: 0.0974 - val_binary_accuracy: 0.9699

Epoch 00057: val_loss did not improve from 0.08894814
Epoch 58/100
 - 5604s - loss: 0.0943 - binary_accuracy: 0.9686 - val_loss: 0.0937 - val_binary_accuracy: 0.9705

Epoch 00058: val_loss did not improve from 0.08894814
Epoch 59/100
 - 5524s - loss: 0.0944 - binary_accuracy: 0.9686 - val_loss: 0.0943 - val_binary_accuracy: 0.9703

Epoch 00059: val_loss did not improve from 0.08894814
Epoch 60/100


PS:

Read file <./cluster_err/ResNet18_KFold_4_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng06>
Subject: Job 46227122: <ResNet18_KFold_4> in cluster <rcc> Exited

Job <ResNet18_KFold_4> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Tue Dec 18 19:13:09 2018
Job was executed on host(s) <lng06>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Tue Dec 18 19:50:34 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Tue Dec 18 19:50:34 2018
Terminated at Wed Dec 19 13:41:46 2018
Results reported at Wed Dec 19 13:41:46 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 4
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   263493.00 sec.
    Max Memory :                                 41633 MB
    Average Memory :                             37039.86 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               60767.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   64272 sec.
    Turnaround time :                            66517 sec.

The output (if any) follows:

Training model on 84572 samples, validate on 21105 samples
Epoch 1/100
 - 3670s - loss: 0.0929 - binary_accuracy: 0.9690 - val_loss: 0.0849 - val_binary_accuracy: 0.9716

Epoch 00001: val_loss improved from 0.08894814 to 0.08489089, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 2/100
 - 3587s - loss: 0.0921 - binary_accuracy: 0.9693 - val_loss: 0.0835 - val_binary_accuracy: 0.9717

Epoch 00002: val_loss improved from 0.08489089 to 0.08346072, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 3/100
 - 3634s - loss: 0.0917 - binary_accuracy: 0.9695 - val_loss: 0.0838 - val_binary_accuracy: 0.9719

Epoch 00003: val_loss did not improve from 0.08346072
Epoch 4/100
 - 4675s - loss: 0.0917 - binary_accuracy: 0.9695 - val_loss: 0.0826 - val_binary_accuracy: 0.9720

Epoch 00004: val_loss improved from 0.08346072 to 0.08262534, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 5/100
 - 5295s - loss: 0.0913 - binary_accuracy: 0.9695 - val_loss: 0.0826 - val_binary_accuracy: 0.9720

Epoch 00005: val_loss improved from 0.08262534 to 0.08262046, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 6/100
 - 5187s - loss: 0.0915 - binary_accuracy: 0.9695 - val_loss: 0.0829 - val_binary_accuracy: 0.9720

Epoch 00006: val_loss did not improve from 0.08262046
Epoch 7/100
 - 4922s - loss: 0.0912 - binary_accuracy: 0.9697 - val_loss: 0.0821 - val_binary_accuracy: 0.9720

Epoch 00007: val_loss improved from 0.08262046 to 0.08208671, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 8/100
 - 5243s - loss: 0.0911 - binary_accuracy: 0.9697 - val_loss: 0.0826 - val_binary_accuracy: 0.9722

Epoch 00008: val_loss did not improve from 0.08208671
Epoch 9/100
 - 5291s - loss: 0.0909 - binary_accuracy: 0.9698 - val_loss: 0.0830 - val_binary_accuracy: 0.9719

Epoch 00009: val_loss did not improve from 0.08208671
Epoch 10/100
 - 5258s - loss: 0.0909 - binary_accuracy: 0.9698 - val_loss: 0.0821 - val_binary_accuracy: 0.9720

Epoch 00010: val_loss did not improve from 0.08208671
Epoch 11/100
 - 5426s - loss: 0.0907 - binary_accuracy: 0.9699 - val_loss: 0.0823 - val_binary_accuracy: 0.9723

Epoch 00011: val_loss did not improve from 0.08208671
Epoch 12/100
 - 5409s - loss: 0.0908 - binary_accuracy: 0.9699 - val_loss: 0.0820 - val_binary_accuracy: 0.9722

Epoch 00012: val_loss improved from 0.08208671 to 0.08201623, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 13/100
 - 5310s - loss: 0.0907 - binary_accuracy: 0.9698 - val_loss: 0.0819 - val_binary_accuracy: 0.9721

Epoch 00013: val_loss improved from 0.08201623 to 0.08189072, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 14/100


PS:

Read file <./cluster_err/ResNet18_KFold_4_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng04>
Subject: Job 46232802: <ResNet18_KFold_4> in cluster <rcc> Exited

Job <ResNet18_KFold_4> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 19 13:55:15 2018
Job was executed on host(s) <lng04>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 19 18:50:15 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 19 18:50:15 2018
Terminated at Thu Dec 20 16:10:08 2018
Results reported at Thu Dec 20 16:10:08 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 4
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   362951.00 sec.
    Max Memory :                                 42776 MB
    Average Memory :                             37519.50 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               59624.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   76793 sec.
    Turnaround time :                            94493 sec.

The output (if any) follows:

Training model on 84572 samples, validate on 21105 samples
Epoch 1/100
 - 3562s - loss: 0.0838 - binary_accuracy: 0.9716 - val_loss: 0.0809 - val_binary_accuracy: 0.9725

Epoch 00001: val_loss improved from 0.08189072 to 0.08093765, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 2/100
 - 3567s - loss: 0.0836 - binary_accuracy: 0.9716 - val_loss: 0.0806 - val_binary_accuracy: 0.9725

Epoch 00002: val_loss improved from 0.08093765 to 0.08061872, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 3/100
 - 3652s - loss: 0.0834 - binary_accuracy: 0.9718 - val_loss: 0.0809 - val_binary_accuracy: 0.9724

Epoch 00003: val_loss did not improve from 0.08061872
Epoch 4/100
 - 3676s - loss: 0.0832 - binary_accuracy: 0.9718 - val_loss: 0.0802 - val_binary_accuracy: 0.9727

Epoch 00004: val_loss improved from 0.08061872 to 0.08018137, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 5/100
 - 3770s - loss: 0.0830 - binary_accuracy: 0.9718 - val_loss: 0.0807 - val_binary_accuracy: 0.9725

Epoch 00005: val_loss did not improve from 0.08018137
Epoch 6/100
 - 3972s - loss: 0.0830 - binary_accuracy: 0.9718 - val_loss: 0.0806 - val_binary_accuracy: 0.9723

Epoch 00006: val_loss did not improve from 0.08018137
Epoch 7/100
 - 3726s - loss: 0.0828 - binary_accuracy: 0.9719 - val_loss: 0.0805 - val_binary_accuracy: 0.9725

Epoch 00007: val_loss did not improve from 0.08018137
Epoch 8/100
 - 3729s - loss: 0.0828 - binary_accuracy: 0.9720 - val_loss: 0.0798 - val_binary_accuracy: 0.9727

Epoch 00008: val_loss improved from 0.08018137 to 0.07982563, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 9/100
 - 3736s - loss: 0.0826 - binary_accuracy: 0.9720 - val_loss: 0.0798 - val_binary_accuracy: 0.9728

Epoch 00009: val_loss improved from 0.07982563 to 0.07980693, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 10/100
 - 3875s - loss: 0.0825 - binary_accuracy: 0.9720 - val_loss: 0.0796 - val_binary_accuracy: 0.9728

Epoch 00010: val_loss improved from 0.07980693 to 0.07960768, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 11/100
 - 3655s - loss: 0.0822 - binary_accuracy: 0.9721 - val_loss: 0.0800 - val_binary_accuracy: 0.9725

Epoch 00011: val_loss did not improve from 0.07960768
Epoch 12/100
 - 3538s - loss: 0.0821 - binary_accuracy: 0.9722 - val_loss: 0.0796 - val_binary_accuracy: 0.9727

Epoch 00012: val_loss did not improve from 0.07960768
Epoch 13/100
 - 3633s - loss: 0.0821 - binary_accuracy: 0.9722 - val_loss: 0.0798 - val_binary_accuracy: 0.9726

Epoch 00013: val_loss did not improve from 0.07960768
Epoch 14/100
 - 3674s - loss: 0.0822 - binary_accuracy: 0.9721 - val_loss: 0.0792 - val_binary_accuracy: 0.9728

Epoch 00014: val_loss improved from 0.07960768 to 0.07920334, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 15/100
 - 3854s - loss: 0.0820 - binary_accuracy: 0.9721 - val_loss: 0.0799 - val_binary_accuracy: 0.9725

Epoch 00015: val_loss did not improve from 0.07920334
Epoch 16/100
 - 4932s - loss: 0.0820 - binary_accuracy: 0.9723 - val_loss: 0.0798 - val_binary_accuracy: 0.9727

Epoch 00016: val_loss did not improve from 0.07920334
Epoch 17/100
 - 5239s - loss: 0.0818 - binary_accuracy: 0.9723 - val_loss: 0.0798 - val_binary_accuracy: 0.9727

Epoch 00017: val_loss did not improve from 0.07920334
Epoch 18/100
 - 5050s - loss: 0.0818 - binary_accuracy: 0.9723 - val_loss: 0.0792 - val_binary_accuracy: 0.9728

Epoch 00018: val_loss did not improve from 0.07920334
Epoch 19/100
 - 5145s - loss: 0.0818 - binary_accuracy: 0.9722 - val_loss: 0.0796 - val_binary_accuracy: 0.9727

Epoch 00019: val_loss did not improve from 0.07920334
Epoch 20/100


PS:

Read file <./cluster_err/ResNet18_KFold_4_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng07>
Subject: Job 46244692: <ResNet18_KFold_4> in cluster <rcc> Exited

Job <ResNet18_KFold_4> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Thu Dec 20 16:37:10 2018
Job was executed on host(s) <lng07>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Thu Dec 20 21:30:15 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Thu Dec 20 21:30:15 2018
Terminated at Fri Dec 21 12:17:50 2018
Results reported at Fri Dec 21 12:17:50 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 4
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   129414.23 sec.
    Max Memory :                                 36217 MB
    Average Memory :                             30332.66 MB
    Total Requested Memory :                     60000.00 MB
    Delta Memory :                               23783.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              21
    Max Threads :                                473
    Run time :                                   53255 sec.
    Turnaround time :                            70840 sec.

The output (if any) follows:

Training model on 84572 samples, validate on 21105 samples
Epoch 1/10
 - 6754s - loss: 0.0809 - binary_accuracy: 0.9725 - val_loss: 0.0793 - val_binary_accuracy: 0.9730

Epoch 00001: val_loss did not improve from 0.07920334
Epoch 2/10
 - 7045s - loss: 0.0808 - binary_accuracy: 0.9725 - val_loss: 0.0793 - val_binary_accuracy: 0.9729

Epoch 00002: val_loss did not improve from 0.07920334
Epoch 3/10
 - 5151s - loss: 0.0808 - binary_accuracy: 0.9725 - val_loss: 0.0795 - val_binary_accuracy: 0.9729

Epoch 00003: val_loss did not improve from 0.07920334
Epoch 4/10
 - 6904s - loss: 0.0808 - binary_accuracy: 0.9725 - val_loss: 0.0791 - val_binary_accuracy: 0.9728

Epoch 00004: val_loss improved from 0.07920334 to 0.07911470, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 5/10
 - 6832s - loss: 0.0807 - binary_accuracy: 0.9726 - val_loss: 0.0792 - val_binary_accuracy: 0.9729

Epoch 00005: val_loss did not improve from 0.07911470
Epoch 6/10
 - 6660s - loss: 0.0806 - binary_accuracy: 0.9726 - val_loss: 0.0796 - val_binary_accuracy: 0.9727

Epoch 00006: val_loss did not improve from 0.07911470
Epoch 7/10
 - 6889s - loss: 0.0803 - binary_accuracy: 0.9726 - val_loss: 0.0800 - val_binary_accuracy: 0.9726

Epoch 00007: val_loss did not improve from 0.07911470
Epoch 8/10
 - 6539s - loss: 0.0803 - binary_accuracy: 0.9726 - val_loss: 0.0794 - val_binary_accuracy: 0.9727

Epoch 00008: val_loss did not improve from 0.07911470
Epoch 9/10


PS:

Read file <./cluster_err/ResNet18_KFold_4_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng01>
Subject: Job 46356132: <ResNet18_KFold_4> in cluster <rcc> Exited

Job <ResNet18_KFold_4> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Mon Dec 31 10:37:02 2018
Job was executed on host(s) <lng01>, in queue <normal>, as user <rs619065> in cluster <rcc> at Wed Jan  2 16:21:58 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Jan  2 16:21:58 2019
Terminated at Sun Jan  6 18:59:46 2019
Results reported at Sun Jan  6 18:59:46 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 4
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   916869.44 sec.
    Max Memory :                                 36163 MB
    Average Memory :                             29827.22 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               43837.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              21
    Max Threads :                                473
    Run time :                                   355068 sec.
    Turnaround time :                            548564 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 512)          262656      global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc2[0][0]                        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,148,124
Trainable params: 13,136,348
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84572 samples, validate on 21105 samples
Epoch 1/100
Epoch 1/100
 - 7251s - loss: 0.2243 - binary_accuracy: 0.9161 - val_loss: 0.1333 - val_binary_accuracy: 0.9555

Epoch 00001: val_loss improved from inf to 0.13331127, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 2/100
 - 6754s - loss: 0.1256 - binary_accuracy: 0.9581 - val_loss: 0.1324 - val_binary_accuracy: 0.9583

Epoch 00002: val_loss improved from 0.13331127 to 0.13239144, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 3/100
 - 6551s - loss: 0.1146 - binary_accuracy: 0.9613 - val_loss: 0.1178 - val_binary_accuracy: 0.9615

Epoch 00003: val_loss improved from 0.13239144 to 0.11777818, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 4/100
 - 6468s - loss: 0.1090 - binary_accuracy: 0.9630 - val_loss: 0.1174 - val_binary_accuracy: 0.9610

Epoch 00004: val_loss improved from 0.11777818 to 0.11737770, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 5/100
 - 6499s - loss: 0.1047 - binary_accuracy: 0.9644 - val_loss: 0.0981 - val_binary_accuracy: 0.9666

Epoch 00005: val_loss improved from 0.11737770 to 0.09808454, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 6/100
 - 6720s - loss: 0.1023 - binary_accuracy: 0.9653 - val_loss: 0.1041 - val_binary_accuracy: 0.9640

Epoch 00006: val_loss did not improve from 0.09808454
Epoch 7/100
 - 6403s - loss: 0.1002 - binary_accuracy: 0.9660 - val_loss: 0.0987 - val_binary_accuracy: 0.9665

Epoch 00007: val_loss did not improve from 0.09808454
Epoch 8/100
 - 6391s - loss: 0.0983 - binary_accuracy: 0.9666 - val_loss: 0.0973 - val_binary_accuracy: 0.9673

Epoch 00008: val_loss improved from 0.09808454 to 0.09732073, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 9/100
 - 6442s - loss: 0.0972 - binary_accuracy: 0.9669 - val_loss: 0.0975 - val_binary_accuracy: 0.9674

Epoch 00009: val_loss did not improve from 0.09732073
Epoch 10/100
 - 6743s - loss: 0.0958 - binary_accuracy: 0.9674 - val_loss: 0.0948 - val_binary_accuracy: 0.9676

Epoch 00010: val_loss improved from 0.09732073 to 0.09477623, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 11/100
 - 6617s - loss: 0.0950 - binary_accuracy: 0.9678 - val_loss: 0.0967 - val_binary_accuracy: 0.9663

Epoch 00011: val_loss did not improve from 0.09477623
Epoch 12/100
 - 5976s - loss: 0.0938 - binary_accuracy: 0.9682 - val_loss: 0.0927 - val_binary_accuracy: 0.9684

Epoch 00012: val_loss improved from 0.09477623 to 0.09266200, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 13/100
 - 6802s - loss: 0.0933 - binary_accuracy: 0.9684 - val_loss: 0.0943 - val_binary_accuracy: 0.9680

Epoch 00013: val_loss did not improve from 0.09266200
Epoch 14/100
 - 6868s - loss: 0.0925 - binary_accuracy: 0.9686 - val_loss: 0.0946 - val_binary_accuracy: 0.9679

Epoch 00014: val_loss did not improve from 0.09266200
Epoch 15/100
 - 7828s - loss: 0.0920 - binary_accuracy: 0.9688 - val_loss: 0.0907 - val_binary_accuracy: 0.9682

Epoch 00015: val_loss improved from 0.09266200 to 0.09072750, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 16/100
 - 9216s - loss: 0.0912 - binary_accuracy: 0.9690 - val_loss: 0.0897 - val_binary_accuracy: 0.9697

Epoch 00016: val_loss improved from 0.09072750 to 0.08974797, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 17/100
 - 9039s - loss: 0.0906 - binary_accuracy: 0.9692 - val_loss: 0.0966 - val_binary_accuracy: 0.9669

Epoch 00017: val_loss did not improve from 0.08974797
Epoch 18/100
 - 8647s - loss: 0.0901 - binary_accuracy: 0.9694 - val_loss: 0.0893 - val_binary_accuracy: 0.9698

Epoch 00018: val_loss improved from 0.08974797 to 0.08930196, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 19/100
 - 8591s - loss: 0.0896 - binary_accuracy: 0.9695 - val_loss: 0.0895 - val_binary_accuracy: 0.9696

Epoch 00019: val_loss did not improve from 0.08930196
Epoch 20/100
 - 9386s - loss: 0.0892 - binary_accuracy: 0.9698 - val_loss: 0.0942 - val_binary_accuracy: 0.9669

Epoch 00020: val_loss did not improve from 0.08930196
Epoch 21/100
 - 9111s - loss: 0.0887 - binary_accuracy: 0.9699 - val_loss: 0.0917 - val_binary_accuracy: 0.9674

Epoch 00021: val_loss did not improve from 0.08930196
Epoch 22/100
 - 10138s - loss: 0.0885 - binary_accuracy: 0.9699 - val_loss: 0.0877 - val_binary_accuracy: 0.9694

Epoch 00022: val_loss improved from 0.08930196 to 0.08773534, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 23/100
 - 8931s - loss: 0.0881 - binary_accuracy: 0.9701 - val_loss: 0.0886 - val_binary_accuracy: 0.9691

Epoch 00023: val_loss did not improve from 0.08773534
Epoch 24/100
 - 9018s - loss: 0.0879 - binary_accuracy: 0.9702 - val_loss: 0.0849 - val_binary_accuracy: 0.9710

Epoch 00024: val_loss improved from 0.08773534 to 0.08487611, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 25/100
 - 7633s - loss: 0.0873 - binary_accuracy: 0.9703 - val_loss: 0.0873 - val_binary_accuracy: 0.9695

Epoch 00025: val_loss did not improve from 0.08487611
Epoch 26/100
 - 7773s - loss: 0.0870 - binary_accuracy: 0.9704 - val_loss: 0.0882 - val_binary_accuracy: 0.9692

Epoch 00026: val_loss did not improve from 0.08487611
Epoch 27/100
 - 7145s - loss: 0.0868 - binary_accuracy: 0.9705 - val_loss: 0.0925 - val_binary_accuracy: 0.9683

Epoch 00027: val_loss did not improve from 0.08487611
Epoch 28/100
 - 7312s - loss: 0.0862 - binary_accuracy: 0.9707 - val_loss: 0.0889 - val_binary_accuracy: 0.9690

Epoch 00028: val_loss did not improve from 0.08487611
Epoch 29/100
 - 7086s - loss: 0.0861 - binary_accuracy: 0.9707 - val_loss: 0.0850 - val_binary_accuracy: 0.9712

Epoch 00029: val_loss did not improve from 0.08487611

Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.99999974738e-06.
Epoch 30/100
 - 6802s - loss: 0.0825 - binary_accuracy: 0.9720 - val_loss: 0.0786 - val_binary_accuracy: 0.9726

Epoch 00030: val_loss improved from 0.08487611 to 0.07860235, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 31/100
 - 6799s - loss: 0.0815 - binary_accuracy: 0.9723 - val_loss: 0.0778 - val_binary_accuracy: 0.9728

Epoch 00031: val_loss improved from 0.07860235 to 0.07776948, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 32/100
 - 6671s - loss: 0.0815 - binary_accuracy: 0.9723 - val_loss: 0.0778 - val_binary_accuracy: 0.9729

Epoch 00032: val_loss did not improve from 0.07776948
Epoch 33/100
 - 6822s - loss: 0.0811 - binary_accuracy: 0.9723 - val_loss: 0.0775 - val_binary_accuracy: 0.9729

Epoch 00033: val_loss improved from 0.07776948 to 0.07754244, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 34/100
 - 7094s - loss: 0.0808 - binary_accuracy: 0.9724 - val_loss: 0.0777 - val_binary_accuracy: 0.9729

Epoch 00034: val_loss did not improve from 0.07754244
Epoch 35/100
 - 6564s - loss: 0.0807 - binary_accuracy: 0.9725 - val_loss: 0.0777 - val_binary_accuracy: 0.9729

Epoch 00035: val_loss did not improve from 0.07754244
Epoch 36/100
 - 7061s - loss: 0.0807 - binary_accuracy: 0.9725 - val_loss: 0.0772 - val_binary_accuracy: 0.9732

Epoch 00036: val_loss improved from 0.07754244 to 0.07716024, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 37/100
 - 7477s - loss: 0.0804 - binary_accuracy: 0.9726 - val_loss: 0.0777 - val_binary_accuracy: 0.9731

Epoch 00037: val_loss did not improve from 0.07716024
Epoch 38/100
 - 6421s - loss: 0.0802 - binary_accuracy: 0.9728 - val_loss: 0.0772 - val_binary_accuracy: 0.9731

Epoch 00038: val_loss did not improve from 0.07716024
Epoch 39/100
 - 6385s - loss: 0.0801 - binary_accuracy: 0.9728 - val_loss: 0.0772 - val_binary_accuracy: 0.9731

Epoch 00039: val_loss did not improve from 0.07716024
Epoch 40/100
 - 7176s - loss: 0.0801 - binary_accuracy: 0.9726 - val_loss: 0.0773 - val_binary_accuracy: 0.9729

Epoch 00040: val_loss did not improve from 0.07716024
Epoch 41/100
 - 6868s - loss: 0.0799 - binary_accuracy: 0.9727 - val_loss: 0.0770 - val_binary_accuracy: 0.9731

Epoch 00041: val_loss improved from 0.07716024 to 0.07702955, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 42/100
 - 6796s - loss: 0.0798 - binary_accuracy: 0.9728 - val_loss: 0.0772 - val_binary_accuracy: 0.9731

Epoch 00042: val_loss did not improve from 0.07702955
Epoch 43/100
 - 6728s - loss: 0.0797 - binary_accuracy: 0.9728 - val_loss: 0.0769 - val_binary_accuracy: 0.9731

Epoch 00043: val_loss improved from 0.07702955 to 0.07690849, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 44/100
 - 6885s - loss: 0.0795 - binary_accuracy: 0.9728 - val_loss: 0.0771 - val_binary_accuracy: 0.9730

Epoch 00044: val_loss did not improve from 0.07690849
Epoch 45/100
 - 7863s - loss: 0.0796 - binary_accuracy: 0.9728 - val_loss: 0.0768 - val_binary_accuracy: 0.9730

Epoch 00045: val_loss improved from 0.07690849 to 0.07680954, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 46/100
 - 7105s - loss: 0.0796 - binary_accuracy: 0.9729 - val_loss: 0.0770 - val_binary_accuracy: 0.9729

Epoch 00046: val_loss did not improve from 0.07680954
Epoch 47/100
 - 6568s - loss: 0.0793 - binary_accuracy: 0.9730 - val_loss: 0.0773 - val_binary_accuracy: 0.9729

Epoch 00047: val_loss did not improve from 0.07680954
Epoch 48/100
 - 7906s - loss: 0.0794 - binary_accuracy: 0.9729 - val_loss: 0.0775 - val_binary_accuracy: 0.9729

Epoch 00048: val_loss did not improve from 0.07680954

Epoch 00048: ReduceLROnPlateau reducing learning rate to 1e-06.
Epoch 49/100


PS:

Read file <./cluster_err/ResNet18_KFold_4_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng01>
Subject: Job 46386072: <ResNet18_KFold_4> in cluster <rcc> Exited

Job <ResNet18_KFold_4> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Sun Jan  6 19:01:21 2019
Job was executed on host(s) <lng01>, in queue <normal>, as user <rs619065> in cluster <rcc> at Sun Jan  6 19:18:45 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Sun Jan  6 19:18:45 2019
Terminated at Sun Jan  6 23:17:35 2019
Results reported at Sun Jan  6 23:17:35 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 4
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   38445.41 sec.
    Max Memory :                                 59722 MB
    Average Memory :                             42851.33 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               20278.00 MB
    Max Swap :                                   -
    Max Processes :                              21
    Max Threads :                                473
    Run time :                                   14330 sec.
    Turnaround time :                            15374 sec.

The output (if any) follows:

Training model on 84572 samples, validate on 21105 samples
Epoch 1/100
Epoch 1/100
 - 6993s - loss: 0.0779 - binary_accuracy: 0.9731 - val_loss: 0.0799 - val_binary_accuracy: 0.9721

Epoch 00001: val_loss did not improve from 0.07680954
Epoch 2/100
 - 6699s - loss: 0.0777 - binary_accuracy: 0.9731 - val_loss: 0.0838 - val_binary_accuracy: 0.9709

Epoch 00002: val_loss did not improve from 0.07680954
Epoch 3/100


PS:

Read file <./cluster_err/ResNet18_KFold_4_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng03>
Subject: Job 46386639: <ResNet18_KFold_4> in cluster <rcc> Exited

Job <ResNet18_KFold_4> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Sun Jan  6 23:18:00 2019
Job was executed on host(s) <lng03>, in queue <normal>, as user <rs619065> in cluster <rcc> at Sun Jan  6 23:22:02 2019
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Sun Jan  6 23:22:02 2019
Terminated at Mon Jan  7 12:36:09 2019
Results reported at Mon Jan  7 12:36:09 2019

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 4
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   129925.00 sec.
    Max Memory :                                 65249 MB
    Average Memory :                             51331.25 MB
    Total Requested Memory :                     80000.00 MB
    Delta Memory :                               14751.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              22
    Max Threads :                                473
    Run time :                                   47647 sec.
    Turnaround time :                            47889 sec.

The output (if any) follows:

Training model on 84572 samples, validate on 21105 samples
Epoch 1/100
 - 7200s - loss: 0.0760 - binary_accuracy: 0.9737 - val_loss: 0.0754 - val_binary_accuracy: 0.9735

Epoch 00001: val_loss improved from 0.07680954 to 0.07538176, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 2/100
 - 6903s - loss: 0.0759 - binary_accuracy: 0.9737 - val_loss: 0.0752 - val_binary_accuracy: 0.9736

Epoch 00002: val_loss improved from 0.07538176 to 0.07518200, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 3/100
 - 6487s - loss: 0.0757 - binary_accuracy: 0.9739 - val_loss: 0.0749 - val_binary_accuracy: 0.9737

Epoch 00003: val_loss improved from 0.07518200 to 0.07485753, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 4/100
 - 6524s - loss: 0.0756 - binary_accuracy: 0.9738 - val_loss: 0.0750 - val_binary_accuracy: 0.9737

Epoch 00004: val_loss did not improve from 0.07485753
Epoch 5/100
 - 6461s - loss: 0.0756 - binary_accuracy: 0.9738 - val_loss: 0.0750 - val_binary_accuracy: 0.9737

Epoch 00005: val_loss did not improve from 0.07485753
Epoch 6/100
 - 6589s - loss: 0.0753 - binary_accuracy: 0.9739 - val_loss: 0.0747 - val_binary_accuracy: 0.9738

Epoch 00006: val_loss improved from 0.07485753 to 0.07474545, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 7/100
 - 6826s - loss: 0.0753 - binary_accuracy: 0.9739 - val_loss: 0.0747 - val_binary_accuracy: 0.9737

Epoch 00007: val_loss improved from 0.07474545 to 0.07467888, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_4.h5
Epoch 8/100


PS:

Read file <./cluster_err/ResNet18_KFold_4_err.txt> for stderr output of this job.

