Sender: LSF System <lsfadmin@lng06>
Subject: Job 46184808: <ResNet18_KFold_1> in cluster <rcc> Done

Job <ResNet18_KFold_1> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 12 01:29:50 2018
Job was executed on host(s) <lng06>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 12 09:48:54 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 12 09:48:54 2018
Terminated at Mon Dec 17 01:06:58 2018
Results reported at Mon Dec 17 01:06:58 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1281188.75 sec.
    Max Memory :                                 42000 MB
    Average Memory :                             36142.96 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               60400.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   400684 sec.
    Turnaround time :                            430628 sec.

The output (if any) follows:

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 1024, 1024, 3 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 1030, 1030, 3 0           data[0][0]                       
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 512, 512, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, 512, 512, 64) 256         conv1[0][0]                      
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 512, 512, 64) 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 514, 514, 64) 0           activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_2[0][0]               
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, 256, 256, 64) 36928       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 256, 64) 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, 256, 256, 64) 256         res2a_branch1[0][0]              
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 256, 64) 0           activation_3[0][0]               
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 256, 256, 64) 0           add_1[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, 256, 256, 64) 36928       activation_4[0][0]               
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, 256, 256, 64) 36928       activation_5[0][0]               
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, 256, 256, 64) 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 256, 64) 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
add_2 (Add)                     (None, 256, 256, 64) 0           activation_6[0][0]               
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 256, 64) 0           add_2[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 128, 128, 128 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_8[0][0]               
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, 128, 128, 128 73856       activation_7[0][0]               
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 128 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, 128, 128, 128 512         res3a_branch1[0][0]              
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 128, 128 0           activation_9[0][0]               
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 128, 128, 128 0           add_3[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, 128, 128, 128 147584      activation_10[0][0]              
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 128, 128 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, 128, 128, 128 147584      activation_11[0][0]              
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, 128, 128, 128 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 128, 128 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
add_4 (Add)                     (None, 128, 128, 128 0           activation_12[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 128, 128, 128 0           add_4[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_14[0][0]              
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, 64, 64, 256)  295168      activation_13[0][0]              
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 64, 64, 256)  0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res4a_branch1[0][0]              
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 64, 256)  0           activation_15[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 64, 64, 256)  0           add_5[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, 64, 64, 256)  590080      activation_16[0][0]              
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, 64, 64, 256)  590080      activation_17[0][0]              
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, 64, 64, 256)  1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 64, 64, 256)  0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
add_6 (Add)                     (None, 64, 64, 256)  0           activation_18[0][0]              
                                                                 activation_16[0][0]              
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 64, 64, 256)  0           add_6[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_20[0][0]              
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, 32, 32, 512)  1180160     activation_19[0][0]              
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 512)  0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res5a_branch1[0][0]              
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 512)  0           activation_21[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, 32, 32, 512)  2359808     activation_22[0][0]              
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, 32, 32, 512)  2359808     activation_23[0][0]              
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, 32, 32, 512)  2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 512)  0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 512)  0           activation_24[0][0]              
                                                                 activation_22[0][0]              
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 512)  0           add_8[0][0]                      
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 64)           0           res2a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 128)          0           res3a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_4 (Glo (None, 256)          0           res4a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_5 (Glo (None, 512)          0           res5a_branch1[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           activation_25[0][0]              
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1472)         0           global_average_pooling2d_2[0][0] 
                                                                 global_average_pooling2d_3[0][0] 
                                                                 global_average_pooling2d_4[0][0] 
                                                                 global_average_pooling2d_5[0][0] 
                                                                 global_average_pooling2d_1[0][0] 
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 512)          754176      concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_1 (BatchNormalization)    (None, 512)          2048        fc1[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           batch_1[0][0]                    
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_2 (BatchNormalization)    (None, 512)          2048        fc2[0][0]                        
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           batch_2[0][0]                    
__________________________________________________________________________________________________
fc28 (Dense)                    (None, 28)           14364       dropout_2[0][0]                  
==================================================================================================
Total params: 13,639,644
Trainable params: 13,627,868
Non-trainable params: 11,776
__________________________________________________________________________________________________
Training model on 84546 samples, validate on 21131 samples
Epoch 1/100
 - 9127s - loss: 0.3226 - binary_accuracy: 0.8662 - val_loss: 0.1467 - val_binary_accuracy: 0.9533

Epoch 00001: val_loss improved from inf to 0.14672626, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 2/100
 - 8424s - loss: 0.1530 - binary_accuracy: 0.9507 - val_loss: 0.1415 - val_binary_accuracy: 0.9542

Epoch 00002: val_loss improved from 0.14672626 to 0.14151484, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 3/100
 - 7486s - loss: 0.1362 - binary_accuracy: 0.9552 - val_loss: 0.1317 - val_binary_accuracy: 0.9574

Epoch 00003: val_loss improved from 0.14151484 to 0.13168881, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 4/100
 - 8375s - loss: 0.1262 - binary_accuracy: 0.9583 - val_loss: 0.1328 - val_binary_accuracy: 0.9563

Epoch 00004: val_loss did not improve from 0.13168881
Epoch 5/100
 - 7882s - loss: 0.1203 - binary_accuracy: 0.9601 - val_loss: 0.1116 - val_binary_accuracy: 0.9629

Epoch 00005: val_loss improved from 0.13168881 to 0.11155269, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 6/100
 - 7330s - loss: 0.1162 - binary_accuracy: 0.9613 - val_loss: 0.1637 - val_binary_accuracy: 0.9504

Epoch 00006: val_loss did not improve from 0.11155269
Epoch 7/100
 - 6839s - loss: 0.1138 - binary_accuracy: 0.9619 - val_loss: 0.1080 - val_binary_accuracy: 0.9644

Epoch 00007: val_loss improved from 0.11155269 to 0.10799525, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 8/100
 - 13761s - loss: 0.1117 - binary_accuracy: 0.9626 - val_loss: 0.1125 - val_binary_accuracy: 0.9614

Epoch 00008: val_loss did not improve from 0.10799525
Epoch 9/100
 - 6917s - loss: 0.1099 - binary_accuracy: 0.9632 - val_loss: 0.1259 - val_binary_accuracy: 0.9578

Epoch 00009: val_loss did not improve from 0.10799525
Epoch 10/100
 - 7955s - loss: 0.1081 - binary_accuracy: 0.9636 - val_loss: 0.1087 - val_binary_accuracy: 0.9644

Epoch 00010: val_loss did not improve from 0.10799525
Epoch 11/100
 - 6021s - loss: 0.1072 - binary_accuracy: 0.9638 - val_loss: 0.1087 - val_binary_accuracy: 0.9643

Epoch 00011: val_loss did not improve from 0.10799525
Epoch 12/100
 - 9953s - loss: 0.1062 - binary_accuracy: 0.9643 - val_loss: 0.1263 - val_binary_accuracy: 0.9561

Epoch 00012: val_loss did not improve from 0.10799525
Epoch 13/100
 - 6205s - loss: 0.1054 - binary_accuracy: 0.9646 - val_loss: 0.1372 - val_binary_accuracy: 0.9595

Epoch 00013: val_loss did not improve from 0.10799525
Epoch 14/100
 - 6595s - loss: 0.1045 - binary_accuracy: 0.9648 - val_loss: 0.1043 - val_binary_accuracy: 0.9668

Epoch 00014: val_loss improved from 0.10799525 to 0.10426603, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 15/100
 - 7714s - loss: 0.1037 - binary_accuracy: 0.9652 - val_loss: 0.1064 - val_binary_accuracy: 0.9658

Epoch 00015: val_loss did not improve from 0.10426603
Epoch 16/100
 - 5723s - loss: 0.1032 - binary_accuracy: 0.9654 - val_loss: 0.1020 - val_binary_accuracy: 0.9661

Epoch 00016: val_loss improved from 0.10426603 to 0.10196973, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 17/100
 - 5730s - loss: 0.1025 - binary_accuracy: 0.9656 - val_loss: 0.1066 - val_binary_accuracy: 0.9656

Epoch 00017: val_loss did not improve from 0.10196973
Epoch 18/100
 - 6222s - loss: 0.1021 - binary_accuracy: 0.9658 - val_loss: 0.1003 - val_binary_accuracy: 0.9669

Epoch 00018: val_loss improved from 0.10196973 to 0.10030186, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 19/100
 - 6154s - loss: 0.1015 - binary_accuracy: 0.9660 - val_loss: 0.1051 - val_binary_accuracy: 0.9649

Epoch 00019: val_loss did not improve from 0.10030186
Epoch 20/100
 - 6785s - loss: 0.1011 - binary_accuracy: 0.9661 - val_loss: 0.1269 - val_binary_accuracy: 0.9564

Epoch 00020: val_loss did not improve from 0.10030186
Epoch 21/100
 - 6837s - loss: 0.1007 - binary_accuracy: 0.9663 - val_loss: 0.0950 - val_binary_accuracy: 0.9685

Epoch 00021: val_loss improved from 0.10030186 to 0.09500721, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 22/100
 - 5756s - loss: 0.1004 - binary_accuracy: 0.9663 - val_loss: 0.1049 - val_binary_accuracy: 0.9651

Epoch 00022: val_loss did not improve from 0.09500721
Epoch 23/100
 - 6174s - loss: 0.0998 - binary_accuracy: 0.9664 - val_loss: 0.0949 - val_binary_accuracy: 0.9682

Epoch 00023: val_loss improved from 0.09500721 to 0.09486086, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 24/100
 - 15635s - loss: 0.0997 - binary_accuracy: 0.9665 - val_loss: 0.0964 - val_binary_accuracy: 0.9674

Epoch 00024: val_loss did not improve from 0.09486086
Epoch 25/100
 - 6528s - loss: 0.0992 - binary_accuracy: 0.9668 - val_loss: 0.0988 - val_binary_accuracy: 0.9683

Epoch 00025: val_loss did not improve from 0.09486086
Epoch 26/100
 - 7230s - loss: 0.0989 - binary_accuracy: 0.9668 - val_loss: 0.0997 - val_binary_accuracy: 0.9661

Epoch 00026: val_loss did not improve from 0.09486086
Epoch 27/100
 - 5698s - loss: 0.0990 - binary_accuracy: 0.9669 - val_loss: 0.1207 - val_binary_accuracy: 0.9645

Epoch 00027: val_loss did not improve from 0.09486086
Epoch 28/100
 - 7701s - loss: 0.0990 - binary_accuracy: 0.9667 - val_loss: 0.1030 - val_binary_accuracy: 0.9681

Epoch 00028: val_loss did not improve from 0.09486086
Epoch 29/100
 - 5959s - loss: 0.0986 - binary_accuracy: 0.9670 - val_loss: 0.0944 - val_binary_accuracy: 0.9686

Epoch 00029: val_loss improved from 0.09486086 to 0.09436613, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 30/100
 - 5689s - loss: 0.0984 - binary_accuracy: 0.9671 - val_loss: 0.0922 - val_binary_accuracy: 0.9693

Epoch 00030: val_loss improved from 0.09436613 to 0.09222520, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 31/100
 - 6310s - loss: 0.0984 - binary_accuracy: 0.9671 - val_loss: 0.0939 - val_binary_accuracy: 0.9691

Epoch 00031: val_loss did not improve from 0.09222520
Epoch 32/100
 - 5606s - loss: 0.0982 - binary_accuracy: 0.9672 - val_loss: 0.0960 - val_binary_accuracy: 0.9676

Epoch 00032: val_loss did not improve from 0.09222520
Epoch 33/100
 - 5476s - loss: 0.0985 - binary_accuracy: 0.9671 - val_loss: 0.0898 - val_binary_accuracy: 0.9694

Epoch 00033: val_loss improved from 0.09222520 to 0.08976449, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 34/100
 - 5381s - loss: 0.0979 - binary_accuracy: 0.9674 - val_loss: 0.1008 - val_binary_accuracy: 0.9659

Epoch 00034: val_loss did not improve from 0.08976449
Epoch 35/100
 - 5477s - loss: 0.0978 - binary_accuracy: 0.9673 - val_loss: 0.0977 - val_binary_accuracy: 0.9683

Epoch 00035: val_loss did not improve from 0.08976449
Epoch 36/100
 - 6187s - loss: 0.0979 - binary_accuracy: 0.9674 - val_loss: 0.0969 - val_binary_accuracy: 0.9693

Epoch 00036: val_loss did not improve from 0.08976449
Epoch 37/100
 - 5685s - loss: 0.0979 - binary_accuracy: 0.9674 - val_loss: 0.0983 - val_binary_accuracy: 0.9685

Epoch 00037: val_loss did not improve from 0.08976449
Epoch 38/100
 - 5465s - loss: 0.0982 - binary_accuracy: 0.9673 - val_loss: 0.0940 - val_binary_accuracy: 0.9695

Epoch 00038: val_loss did not improve from 0.08976449
Epoch 39/100
 - 5630s - loss: 0.0978 - binary_accuracy: 0.9674 - val_loss: 0.0996 - val_binary_accuracy: 0.9664

Epoch 00039: val_loss did not improve from 0.08976449
Epoch 40/100
 - 5273s - loss: 0.0979 - binary_accuracy: 0.9674 - val_loss: 0.0904 - val_binary_accuracy: 0.9700

Epoch 00040: val_loss did not improve from 0.08976449
Epoch 41/100
 - 5443s - loss: 0.0976 - binary_accuracy: 0.9675 - val_loss: 0.0909 - val_binary_accuracy: 0.9697

Epoch 00041: val_loss did not improve from 0.08976449
Epoch 42/100
 - 5415s - loss: 0.0976 - binary_accuracy: 0.9675 - val_loss: 0.0972 - val_binary_accuracy: 0.9694

Epoch 00042: val_loss did not improve from 0.08976449
Epoch 43/100
 - 5701s - loss: 0.0971 - binary_accuracy: 0.9676 - val_loss: 0.0926 - val_binary_accuracy: 0.9697

Epoch 00043: val_loss did not improve from 0.08976449
Epoch 44/100
 - 5215s - loss: 0.0969 - binary_accuracy: 0.9676 - val_loss: 0.0922 - val_binary_accuracy: 0.9700

Epoch 00044: val_loss did not improve from 0.08976449
Epoch 45/100
 - 5385s - loss: 0.0968 - binary_accuracy: 0.9677 - val_loss: 0.1043 - val_binary_accuracy: 0.9676

Epoch 00045: val_loss did not improve from 0.08976449
Epoch 46/100
 - 5484s - loss: 0.0966 - binary_accuracy: 0.9678 - val_loss: 0.0969 - val_binary_accuracy: 0.9683

Epoch 00046: val_loss did not improve from 0.08976449
Epoch 47/100
 - 5361s - loss: 0.0965 - binary_accuracy: 0.9678 - val_loss: 0.4515 - val_binary_accuracy: 0.9505

Epoch 00047: val_loss did not improve from 0.08976449
Epoch 48/100
 - 5383s - loss: 0.0966 - binary_accuracy: 0.9678 - val_loss: 0.0889 - val_binary_accuracy: 0.9705

Epoch 00048: val_loss improved from 0.08976449 to 0.08893236, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 49/100
 - 5401s - loss: 0.0964 - binary_accuracy: 0.9679 - val_loss: 0.0984 - val_binary_accuracy: 0.9665

Epoch 00049: val_loss did not improve from 0.08893236
Epoch 50/100
 - 5421s - loss: 0.0964 - binary_accuracy: 0.9678 - val_loss: 0.1045 - val_binary_accuracy: 0.9682

Epoch 00050: val_loss did not improve from 0.08893236
Epoch 51/100
 - 5489s - loss: 0.0960 - binary_accuracy: 0.9679 - val_loss: 0.0921 - val_binary_accuracy: 0.9702

Epoch 00051: val_loss did not improve from 0.08893236
Epoch 52/100
 - 5515s - loss: 0.0962 - binary_accuracy: 0.9680 - val_loss: 0.0896 - val_binary_accuracy: 0.9707

Epoch 00052: val_loss did not improve from 0.08893236
Epoch 53/100
 - 5516s - loss: 0.0960 - binary_accuracy: 0.9681 - val_loss: 0.0905 - val_binary_accuracy: 0.9705

Epoch 00053: val_loss did not improve from 0.08893236
Epoch 54/100
 - 5497s - loss: 0.0960 - binary_accuracy: 0.9680 - val_loss: 0.0960 - val_binary_accuracy: 0.9683

Epoch 00054: val_loss did not improve from 0.08893236
Epoch 55/100
 - 5361s - loss: 0.0958 - binary_accuracy: 0.9681 - val_loss: 0.0920 - val_binary_accuracy: 0.9691

Epoch 00055: val_loss did not improve from 0.08893236
Epoch 56/100
 - 5326s - loss: 0.0955 - binary_accuracy: 0.9683 - val_loss: 0.0934 - val_binary_accuracy: 0.9699

Epoch 00056: val_loss did not improve from 0.08893236
Epoch 57/100
 - 5346s - loss: 0.0951 - binary_accuracy: 0.9684 - val_loss: 0.0910 - val_binary_accuracy: 0.9695

Epoch 00057: val_loss did not improve from 0.08893236
Epoch 58/100
 - 5793s - loss: 0.0952 - binary_accuracy: 0.9683 - val_loss: 0.0920 - val_binary_accuracy: 0.9705

Epoch 00058: val_loss did not improve from 0.08893236
Epoch 59/100
 - 5531s - loss: 0.0950 - binary_accuracy: 0.9684 - val_loss: 0.0893 - val_binary_accuracy: 0.9706

Epoch 00059: val_loss did not improve from 0.08893236
Epoch 60/100
 - 5284s - loss: 0.0951 - binary_accuracy: 0.9684 - val_loss: 0.0871 - val_binary_accuracy: 0.9709

Epoch 00060: val_loss improved from 0.08893236 to 0.08707174, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 61/100
 - 5433s - loss: 0.0948 - binary_accuracy: 0.9684 - val_loss: 0.0868 - val_binary_accuracy: 0.9706

Epoch 00061: val_loss improved from 0.08707174 to 0.08678614, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 62/100

Epoch 00061: val_loss improved from 0.08707174 to 0.08678614, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
 - 5380s - loss: 0.0944 - binary_accuracy: 0.9686 - val_loss: 0.0896 - val_binary_accuracy: 0.9700

Epoch 00062: val_loss did not improve from 0.08678614
Stopping after 396000 seconds.
complete!!


PS:

Read file <./cluster_err/ResNet18_KFold_1_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng03>
Subject: Job 46226570: <ResNet18_KFold_1> in cluster <rcc> Exited

Job <ResNet18_KFold_1> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Tue Dec 18 17:54:54 2018
Job was executed on host(s) <lng03>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Tue Dec 18 19:41:42 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Tue Dec 18 19:41:42 2018
Terminated at Wed Dec 19 13:41:00 2018
Results reported at Wed Dec 19 13:41:00 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 1
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   239879.38 sec.
    Max Memory :                                 39907 MB
    Average Memory :                             35402.06 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               62493.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              37
    Max Threads :                                873
    Run time :                                   64758 sec.
    Turnaround time :                            71166 sec.

The output (if any) follows:

Training model on 84546 samples, validate on 21131 samples
Epoch 1/100
 - 5189s - loss: 0.0921 - binary_accuracy: 0.9694 - val_loss: 0.0812 - val_binary_accuracy: 0.9728

Epoch 00001: val_loss improved from 0.08678614 to 0.08124131, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 2/100
 - 5717s - loss: 0.0912 - binary_accuracy: 0.9698 - val_loss: 0.0811 - val_binary_accuracy: 0.9729

Epoch 00002: val_loss improved from 0.08124131 to 0.08108746, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 3/100
 - 5649s - loss: 0.0909 - binary_accuracy: 0.9698 - val_loss: 0.0808 - val_binary_accuracy: 0.9730

Epoch 00003: val_loss improved from 0.08108746 to 0.08081740, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 4/100
 - 5775s - loss: 0.0908 - binary_accuracy: 0.9699 - val_loss: 0.0805 - val_binary_accuracy: 0.9730

Epoch 00004: val_loss improved from 0.08081740 to 0.08048894, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 5/100
 - 5732s - loss: 0.0905 - binary_accuracy: 0.9700 - val_loss: 0.0804 - val_binary_accuracy: 0.9729

Epoch 00005: val_loss improved from 0.08048894 to 0.08040202, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 6/100
 - 5278s - loss: 0.0905 - binary_accuracy: 0.9699 - val_loss: 0.0802 - val_binary_accuracy: 0.9731

Epoch 00006: val_loss improved from 0.08040202 to 0.08016114, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 7/100
 - 5827s - loss: 0.0904 - binary_accuracy: 0.9700 - val_loss: 0.0803 - val_binary_accuracy: 0.9730

Epoch 00007: val_loss did not improve from 0.08016114
Epoch 8/100
 - 5383s - loss: 0.0903 - binary_accuracy: 0.9702 - val_loss: 0.0801 - val_binary_accuracy: 0.9731

Epoch 00008: val_loss improved from 0.08016114 to 0.08006609, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 9/100
 - 5689s - loss: 0.0903 - binary_accuracy: 0.9702 - val_loss: 0.0804 - val_binary_accuracy: 0.9730

Epoch 00009: val_loss did not improve from 0.08006609
Epoch 10/100
 - 5790s - loss: 0.0900 - binary_accuracy: 0.9701 - val_loss: 0.0802 - val_binary_accuracy: 0.9730

Epoch 00010: val_loss did not improve from 0.08006609
Epoch 11/100
 - 5658s - loss: 0.0902 - binary_accuracy: 0.9702 - val_loss: 0.0804 - val_binary_accuracy: 0.9730

Epoch 00011: val_loss did not improve from 0.08006609
Epoch 12/100


PS:

Read file <./cluster_err/ResNet18_KFold_1_err.txt> for stderr output of this job.

Sender: LSF System <lsfadmin@lng06>
Subject: Job 46232799: <ResNet18_KFold_1> in cluster <rcc> Exited

Job <ResNet18_KFold_1> was submitted from host <login-g> by user <rs619065> in cluster <rcc> at Wed Dec 19 13:55:14 2018
Job was executed on host(s) <lng06>, in queue <jara-clx>, as user <rs619065> in cluster <rcc> at Wed Dec 19 14:32:32 2018
</home/rs619065> was used as the home directory.
</home/rs619065/HPAIC/src> was used as the working directory.
Started at Wed Dec 19 14:32:32 2018
Terminated at Thu Dec 20 17:13:15 2018
Results reported at Thu Dec 20 17:13:15 2018

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
./train.zsh ResNet18 1
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   406530.16 sec.
    Max Memory :                                 42708 MB
    Average Memory :                             38500.55 MB
    Total Requested Memory :                     102400.00 MB
    Delta Memory :                               59692.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              38
    Max Threads :                                873
    Run time :                                   96043 sec.
    Turnaround time :                            98281 sec.

The output (if any) follows:

Training model on 84546 samples, validate on 21131 samples
Epoch 1/100
 - 3402s - loss: 0.0808 - binary_accuracy: 0.9726 - val_loss: 0.0789 - val_binary_accuracy: 0.9732

Epoch 00001: val_loss improved from 0.08006609 to 0.07894393, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 2/100
 - 3376s - loss: 0.0804 - binary_accuracy: 0.9726 - val_loss: 0.0795 - val_binary_accuracy: 0.9731

Epoch 00002: val_loss did not improve from 0.07894393
Epoch 3/100
 - 3562s - loss: 0.0800 - binary_accuracy: 0.9728 - val_loss: 0.0788 - val_binary_accuracy: 0.9734

Epoch 00003: val_loss improved from 0.07894393 to 0.07881980, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 4/100
 - 3555s - loss: 0.0802 - binary_accuracy: 0.9728 - val_loss: 0.0792 - val_binary_accuracy: 0.9733

Epoch 00004: val_loss did not improve from 0.07881980
Epoch 5/100
 - 3562s - loss: 0.0798 - binary_accuracy: 0.9729 - val_loss: 0.0787 - val_binary_accuracy: 0.9733

Epoch 00005: val_loss improved from 0.07881980 to 0.07870442, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 6/100
 - 4146s - loss: 0.0795 - binary_accuracy: 0.9730 - val_loss: 0.0784 - val_binary_accuracy: 0.9734

Epoch 00006: val_loss improved from 0.07870442 to 0.07837574, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 7/100
 - 5029s - loss: 0.0794 - binary_accuracy: 0.9730 - val_loss: 0.0786 - val_binary_accuracy: 0.9732

Epoch 00007: val_loss did not improve from 0.07837574
Epoch 8/100
 - 5306s - loss: 0.0792 - binary_accuracy: 0.9730 - val_loss: 0.0786 - val_binary_accuracy: 0.9733

Epoch 00008: val_loss did not improve from 0.07837574
Epoch 9/100
 - 5172s - loss: 0.0791 - binary_accuracy: 0.9731 - val_loss: 0.0783 - val_binary_accuracy: 0.9734

Epoch 00009: val_loss improved from 0.07837574 to 0.07829490, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 10/100
 - 5184s - loss: 0.0791 - binary_accuracy: 0.9731 - val_loss: 0.0780 - val_binary_accuracy: 0.9735

Epoch 00010: val_loss improved from 0.07829490 to 0.07801630, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 11/100
 - 5288s - loss: 0.0790 - binary_accuracy: 0.9731 - val_loss: 0.0783 - val_binary_accuracy: 0.9734

Epoch 00011: val_loss did not improve from 0.07801630
Epoch 12/100
 - 5310s - loss: 0.0786 - binary_accuracy: 0.9733 - val_loss: 0.0778 - val_binary_accuracy: 0.9736

Epoch 00012: val_loss improved from 0.07801630 to 0.07782501, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 13/100
 - 5343s - loss: 0.0786 - binary_accuracy: 0.9733 - val_loss: 0.0778 - val_binary_accuracy: 0.9735

Epoch 00013: val_loss improved from 0.07782501 to 0.07776217, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 14/100
 - 5455s - loss: 0.0784 - binary_accuracy: 0.9734 - val_loss: 0.0776 - val_binary_accuracy: 0.9735

Epoch 00014: val_loss improved from 0.07776217 to 0.07757906, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 15/100
 - 5311s - loss: 0.0783 - binary_accuracy: 0.9734 - val_loss: 0.0779 - val_binary_accuracy: 0.9735

Epoch 00015: val_loss did not improve from 0.07757906
Epoch 16/100
 - 5339s - loss: 0.0782 - binary_accuracy: 0.9734 - val_loss: 0.0777 - val_binary_accuracy: 0.9735

Epoch 00016: val_loss did not improve from 0.07757906
Epoch 17/100
 - 5341s - loss: 0.0784 - binary_accuracy: 0.9733 - val_loss: 0.0775 - val_binary_accuracy: 0.9736

Epoch 00017: val_loss improved from 0.07757906 to 0.07753977, saving model to /home/rs619065/HPAIC/model/ResNet18/ResNet18_KFold_1.h5
Epoch 18/100
 - 5303s - loss: 0.0782 - binary_accuracy: 0.9733 - val_loss: 0.0777 - val_binary_accuracy: 0.9736

Epoch 00018: val_loss did not improve from 0.07753977
Epoch 19/100
 - 5300s - loss: 0.0780 - binary_accuracy: 0.9735 - val_loss: 0.0776 - val_binary_accuracy: 0.9736

Epoch 00019: val_loss did not improve from 0.07753977
Epoch 20/100
 - 5410s - loss: 0.0780 - binary_accuracy: 0.9734 - val_loss: 0.0776 - val_binary_accuracy: 0.9735

Epoch 00020: val_loss did not improve from 0.07753977
Epoch 21/100


PS:

Read file <./cluster_err/ResNet18_KFold_1_err.txt> for stderr output of this job.

